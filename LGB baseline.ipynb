{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import sys, os, gc, types\n",
    "import time\n",
    "from subprocess import check_output\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root_paths = [\n",
    "    \"/data/kaggle-wikipedia/data2/\",\n",
    "    \"/Users/jiayou/Dropbox/JuanCode/Kaggle/Wikipedia/data2/\",\n",
    "    \"/Users/jiayou/Dropbox/Documents/JuanCode/Kaggle/Wikipedia/data2/\",\n",
    "    '/Users/junxie/Dropbox/JuanCode/Kaggle/Wikipedia/data2/'\n",
    "]\n",
    "root = None\n",
    "for p in root_paths:\n",
    "    if os.path.exists(p):\n",
    "        root = p\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(root + 'train_2.csv')\n",
    "# train.fillna(0, inplace = True)\n",
    "# train = train.where(train.notnull(), median_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date_df = pd.read_pickle(root + 'date_df.pkl')\n",
    "page_df = pd.read_pickle(root + 'page_ohe.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.drop(train.columns[1:50], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# assign fold number before melt? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train.melt(id_vars=['Page'], var_name='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# construct ABT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "down_sample = None\n",
    "if down_sample is not None:\n",
    "    train_df = train_df[train_df.index % down_sample == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df.merge(page_df, how='left', on='Page')\n",
    "train_df = train_df.merge(date_df, how='left', on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "median_name = [\n",
    "    '49', 'weekday_49', 'weekend_49', \n",
    "    'dow0', 'dow1', 'dow2', 'dow3', 'dow4', 'dow5', 'dow6',\n",
    "    '28', 'weekday_28', 'weekend_28',\n",
    "    '14', 'weekday_14', 'weekend_14',\n",
    "    '21', 'weekday_21', 'weekend_21',\n",
    "#     '35', 'weekday_35', 'weekend_35',\n",
    "#     '42', 'weekday_42', 'weekend_42',\n",
    "    '7',\n",
    "]\n",
    "\n",
    "melted_median = pd.read_pickle(root + 'melted_median_val62_26med.pkl')[median_name + ['Page', 'date']]\n",
    "\n",
    "train_df = train_df.merge(\n",
    "    melted_median, \n",
    "    how='left', \n",
    "    on=['Page','date']\n",
    ")\n",
    "\n",
    "base = '49'\n",
    "\n",
    "for mname in median_name:\n",
    "    train_df['median_{}'.format(mname)] = np.log1p(train_df['median_{}'.format(mname)])\n",
    "for mname in median_name:\n",
    "    if mname != base:\n",
    "        train_df['median_diff_{}'.format(mname)] = train_df['median_{}'.format(mname)] - train_df['median_{}'.format(base)]\n",
    "train_df['value'] = np.log1p(train_df['value']) - train_df['median_{}'.format(base)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# val_days = 62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df['isval'] = (train_df.year == 2017) & (train_df.month >= 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.isval.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for c, dtype in zip(train_df.columns, train_df.dtypes):\n",
    "    if dtype == np.float64:\n",
    "        train_df[c] = train_df[c].astype(np.float32)\n",
    "    if dtype == np.int64:\n",
    "        train_df[c] = train_df[c].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# del median_df, page_df, date_df, train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data and hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.sort_index(axis=1, inplace=True)\n",
    "\n",
    "train = train_df[train_df.isval == False]\n",
    "val = train_df[train_df.isval == True]\n",
    "\n",
    "del train_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_datasets(train, val):\n",
    "    drop_list = ['value', 'isval', 'Page', 'date']\n",
    "    train_value = train.value.values\n",
    "    train.drop(drop_list, axis = 1, inplace=True)\n",
    "\n",
    "    lgb_train = lgb.Dataset(\n",
    "        train.values.astype(np.float32), \n",
    "        train_value.astype(np.float32),\n",
    "        feature_name=list(train.columns),\n",
    "    )\n",
    "    lgb_val = lgb.Dataset(\n",
    "        val.drop(drop_list, axis = 1).values.astype(np.float32), \n",
    "        val.value.values.astype(np.float32), \n",
    "        feature_name=list(train.columns),\n",
    "        reference=lgb_train,\n",
    "    )\n",
    "    return lgb_train, lgb_val\n",
    "\n",
    "lgb_train, lgb_val = create_datasets(train, val)\n",
    "\n",
    "del train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# self-defined eval metric\n",
    "# f(preds: array, train_data: Dataset) -> name: string, value: array, is_higher_better: bool\n",
    "# binary error\n",
    "def SMAPE(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    y_true = np.round(np.expm1(labels))\n",
    "    y_pred = np.round(np.expm1(preds))\n",
    "    loss = np.mean(np.abs(y_true - y_pred) / np.maximum(1e-6, (np.abs(y_true) + np.abs(y_pred)))) * 200\n",
    "    return 'SMAPE', loss, False\n",
    "\n",
    "def SMAPE_2(preds, true):\n",
    "    y_true = np.round(np.expm1(true))\n",
    "    y_pred = np.round(np.expm1(preds))\n",
    "    loss = np.mean(np.abs(y_true - y_pred) / np.maximum(1e-6, (np.abs(y_true) + np.abs(y_pred)))) * 200\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_searches = 5\n",
    "boosting_rounds = 10000\n",
    "stopping_rounds = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "val_abt = val.drop(['value', 'isval', 'Page', 'date'], axis=1)\n",
    "val_pred_list = []\n",
    "\n",
    "for i in range(num_searches):\n",
    "    params = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression_l1',\n",
    "        'metric': {'l1'},\n",
    "        'num_leaves': 512,\n",
    "    #     'min_sum_hessian_in_leaf': 20,\n",
    "        'max_depth': 12,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.85,\n",
    "        'bagging_freq': 3,\n",
    "        'verbose': 1,\n",
    "        'feature_fraction_seed':np.random.randint(0, 1000),\n",
    "        'bagging_seed':np.random.randint(0, 1000),\n",
    "        'data_random_seed':np.random.randint(0, 1000),\n",
    "    #     'device' : 'gpu'\n",
    "    }\n",
    "    name = 'gb12-r{}'.format(i)\n",
    "    print('Start LightGBM training...')\n",
    "    # train\n",
    "    gbm = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=boosting_rounds,\n",
    "#                     feval=SMAPE,\n",
    "                    valid_sets=[lgb_train, lgb_val],\n",
    "#                   categorical_feature=[],\n",
    "                    early_stopping_rounds=stopping_rounds)\n",
    "\n",
    "    print('Save model...')\n",
    "    # save model to file\n",
    "    gbm.save_model('model.{}.txt'.format(name))\n",
    "\n",
    "    print('Plot feature importances...') \n",
    "    ax = lgb.plot_importance(gbm, max_num_features=100, importance_type='gain', title = 'gain', figsize=(20, 20))\n",
    "    plt.show()\n",
    "    ax = lgb.plot_importance(gbm, max_num_features=100, importance_type='split', title = 'split', figsize=(20, 20))\n",
    "    plt.show()\n",
    "    \n",
    "    val_pred = gbm.predict(val_abt, num_iteration=gbm.best_iteration)\n",
    "    val_pred_list.append(val_pred)\n",
    "    print(\n",
    "        'val SMAPE: ', \n",
    "        SMAPE_2(\n",
    "            val_pred + val['median_{}'.format(base)].values, \n",
    "            val.value.values + val['median_{}'.format(base)].values,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_pred = np.mean(\n",
    "    np.concatenate(\n",
    "        [np.expand_dims(val_pred, 1) for val_pred in val_pred_list], \n",
    "        axis=1\n",
    "    ), \n",
    "    axis=1\n",
    ")\n",
    "print(\n",
    "    'ensembled val SMAPE: ', \n",
    "    SMAPE_2(\n",
    "        val_pred + val['median_{}'.format(base)].values, \n",
    "        val.value.values + val['median_{}'.format(base)].values,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.kaggle.com/c/web-traffic-time-series-forecasting/discussion/36780\n",
    "- https://www.kaggle.com/c/web-traffic-time-series-forecasting/discussion/38274#215155"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# name = 'gb4-r0'\n",
    "# gbm = lgb.Booster(model_file='model.{}.txt'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_pickle(root + 'key_2_modified.pkl')\n",
    "\n",
    "test_date_df = pd.read_pickle(root + 'test_date_df.pkl')\n",
    "# page_df = pd.read_pickle(root + 'page_ohe.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "median_data = []\n",
    "median_name = [\n",
    "    '49', 'weekday_49', 'weekend_49', \n",
    "    'dow0', 'dow1', 'dow2', 'dow3', 'dow4', 'dow5', 'dow6', \n",
    "    '28', 'weekday_28', 'weekend_28'\n",
    "]\n",
    "for mname in median_name:\n",
    "    median_data.append(pd.read_pickle(root + 'median_{}.pkl'.format(mname)))\n",
    "    \n",
    "for i in range(len(median_data)):\n",
    "    page_df['median_{}'.format(median_name[i])] = np.log1p(median_data[i].iloc[:, -1])\n",
    "for i in range(len(median_data)):\n",
    "    if i != 0:\n",
    "        page_df['median_diff_{}'.format(median_name[i])] = page_df['median_{}'.format(median_name[i])] - page_df['median_{}'.format(base)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = test.merge(page_df, how='left', on='Page')\n",
    "test = test.merge(test_date_df, how='left', on='date')\n",
    "\n",
    "for c, dtype in zip(test.columns, test.dtypes):\n",
    "    if dtype == np.float64:\n",
    "        test[c] = test[c].astype(np.float32)\n",
    "    if dtype == np.int64:\n",
    "        test[c] = test[c].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.isnull().sum().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.sort_index(axis=1, inplace=True)\n",
    "test_df = test.drop(['Page', 'date', 'Id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "for i in range(num_searches):\n",
    "    name = 'gb12-r{}'.format(i)\n",
    "    gbm = lgb.Booster(model_file='model.{}.txt'.format(name))\n",
    "    pred = gbm.predict(test_df, num_iteration=gbm.best_iteration)\n",
    "    pred_list.append(pred)\n",
    "\n",
    "pred = np.mean(\n",
    "    np.concatenate(\n",
    "        [np.expand_dims(pred, 1) for pred in pred_list], \n",
    "        axis=1\n",
    "    ), \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visit = np.round(np.expm1(pred + test_df['median_{}'.format(base)].values))\n",
    "pred_df = pd.DataFrame({'Id':test.Id,'Visits':visit})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = 'gb12-ensemble'\n",
    "pred_df.to_csv(\n",
    "    os.path.join(root, 'test_prediction.{}.csv'.format(name)), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
