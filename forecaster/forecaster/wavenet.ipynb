{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from dataframe import DataFrame\n",
    "from datareader_wave import DataReader\n",
    "from tf_basemodel import TFBaseModel\n",
    "from tf_utils import (\n",
    "    time_distributed_dense_layer, temporal_convolution_layer,\n",
    "    sequence_mean, sequence_smape, shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/junxie/Dropbox/JuanCode/Insight/project/data_mini/\n"
     ]
    }
   ],
   "source": [
    "root_paths = [\n",
    "    \"/Users/jiayou/Dropbox/JuanCode/Kaggle/Wikipedia/data2/\", # Mac\n",
    "    \"/Users/jiayou/Dropbox/Documents/JuanCode/Kaggle/Wikipedia/data2/\", # 1080\n",
    "    '/Users/junxie/Dropbox/JuanCode/Insight/project/data_mini/', # pro\n",
    "    '/mnt/WD Black/Dropbox/JuanCode/Insight/Project/data_mini/', # paperspace\n",
    "]\n",
    "root = None\n",
    "for p in root_paths:\n",
    "    if os.path.exists(p):\n",
    "        root = p\n",
    "        break\n",
    "print(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class cnn(TFBaseModel):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        residual_channels=32,\n",
    "        skip_channels=32,\n",
    "        dilations=[2**i for i in range(8)]*3,\n",
    "        filter_widths=[2 for i in range(8)]*3,\n",
    "        num_decode_steps=64,\n",
    "        **kwargs\n",
    "    ):\n",
    "        self.residual_channels = residual_channels\n",
    "        self.skip_channels = skip_channels\n",
    "        self.dilations = dilations\n",
    "        self.filter_widths = filter_widths\n",
    "        self.num_decode_steps = num_decode_steps\n",
    "        super(cnn, self).__init__(**kwargs)\n",
    "\n",
    "    def transform(self, x):\n",
    "        return tf.log(x + 1) - tf.expand_dims(self.log_x_encode_mean, 1)\n",
    "\n",
    "    def inverse_transform(self, x):\n",
    "        return tf.exp(x + tf.expand_dims(self.log_x_encode_mean, 1)) - 1\n",
    "\n",
    "    def get_input_sequences(self):\n",
    "        self.x_encode = tf.placeholder(tf.float32, [None, None])\n",
    "        self.encode_len = tf.placeholder(tf.int32, [None])\n",
    "        self.y_decode = tf.placeholder(tf.float32, [None, self.num_decode_steps])\n",
    "        self.decode_len = tf.placeholder(tf.int32, [None])\n",
    "        self.is_nan_encode = tf.placeholder(tf.float32, [None, None])\n",
    "        self.is_nan_decode = tf.placeholder(tf.float32, [None, self.num_decode_steps])\n",
    "\n",
    "        self.page_id = tf.placeholder(tf.int32, [None])\n",
    "        self.project = tf.placeholder(tf.int32, [None])\n",
    "        self.access = tf.placeholder(tf.int32, [None])\n",
    "        self.agent = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "        self.keep_prob = tf.placeholder(tf.float32)\n",
    "        self.is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "        self.log_x_encode_mean = sequence_mean(tf.log(self.x_encode + 1), self.encode_len)\n",
    "        self.log_x_encode = self.transform(self.x_encode)\n",
    "        self.x = tf.expand_dims(self.log_x_encode, 2)\n",
    "\n",
    "        self.encode_features = tf.concat([\n",
    "            tf.expand_dims(self.is_nan_encode, 2),\n",
    "            tf.expand_dims(tf.cast(tf.equal(self.x_encode, 0.0), tf.float32), 2),\n",
    "            tf.tile(tf.reshape(self.log_x_encode_mean, (-1, 1, 1)), (1, tf.shape(self.x_encode)[1], 1)),\n",
    "            tf.tile(tf.expand_dims(tf.one_hot(self.project, 9), 1), (1, tf.shape(self.x_encode)[1], 1)),\n",
    "            tf.tile(tf.expand_dims(tf.one_hot(self.access, 3), 1), (1, tf.shape(self.x_encode)[1], 1)),\n",
    "            tf.tile(tf.expand_dims(tf.one_hot(self.agent, 2), 1), (1, tf.shape(self.x_encode)[1], 1)),\n",
    "        ], axis=2)\n",
    "\n",
    "        decode_idx = tf.tile(tf.expand_dims(tf.range(self.num_decode_steps), 0), (tf.shape(self.y_decode)[0], 1))\n",
    "        self.decode_features = tf.concat([\n",
    "            tf.one_hot(decode_idx, self.num_decode_steps),\n",
    "            tf.tile(tf.reshape(self.log_x_encode_mean, (-1, 1, 1)), (1, self.num_decode_steps, 1)),\n",
    "            tf.tile(tf.expand_dims(tf.one_hot(self.project, 9), 1), (1, self.num_decode_steps, 1)),\n",
    "            tf.tile(tf.expand_dims(tf.one_hot(self.access, 3), 1), (1, self.num_decode_steps, 1)),\n",
    "            tf.tile(tf.expand_dims(tf.one_hot(self.agent, 2), 1), (1, self.num_decode_steps, 1)),\n",
    "        ], axis=2)\n",
    "\n",
    "        return self.x\n",
    "\n",
    "    def encode(self, x, features):\n",
    "        x = tf.concat([x, features], axis=2)\n",
    "\n",
    "        inputs = time_distributed_dense_layer(\n",
    "            inputs=x,\n",
    "            output_units=self.residual_channels,\n",
    "            activation=tf.nn.tanh,\n",
    "            scope='x-proj-encode'\n",
    "        )\n",
    "\n",
    "        skip_outputs = []\n",
    "        conv_inputs = [inputs]\n",
    "        for i, (dilation, filter_width) in enumerate(zip(self.dilations, self.filter_widths)):\n",
    "            dilated_conv = temporal_convolution_layer(\n",
    "                inputs=inputs,\n",
    "                output_units=2*self.residual_channels,\n",
    "                convolution_width=filter_width,\n",
    "                causal=True,\n",
    "                dilation_rate=[dilation],\n",
    "                scope='dilated-conv-encode-{}'.format(i)\n",
    "            )\n",
    "            conv_filter, conv_gate = tf.split(dilated_conv, 2, axis=2)\n",
    "            dilated_conv = tf.nn.tanh(conv_filter)*tf.nn.sigmoid(conv_gate)\n",
    "\n",
    "            outputs = time_distributed_dense_layer(\n",
    "                inputs=dilated_conv,\n",
    "                output_units=self.skip_channels + self.residual_channels,\n",
    "                scope='dilated-conv-proj-encode-{}'.format(i)\n",
    "            )\n",
    "            skips, residuals = tf.split(outputs, [self.skip_channels, self.residual_channels], axis=2)\n",
    "\n",
    "            inputs += residuals\n",
    "            conv_inputs.append(inputs)\n",
    "            skip_outputs.append(skips)\n",
    "\n",
    "        skip_outputs = tf.nn.relu(tf.concat(skip_outputs, axis=2))\n",
    "        h = time_distributed_dense_layer(skip_outputs, 128, scope='dense-encode-1', activation=tf.nn.relu)\n",
    "        y_hat = time_distributed_dense_layer(h, 1, scope='dense-encode-2')\n",
    "\n",
    "        return y_hat, conv_inputs[:-1]\n",
    "\n",
    "    def initialize_decode_params(self, x, features):\n",
    "        x = tf.concat([x, features], axis=2)\n",
    "\n",
    "        inputs = time_distributed_dense_layer(\n",
    "            inputs=x,\n",
    "            output_units=self.residual_channels,\n",
    "            activation=tf.nn.tanh,\n",
    "            scope='x-proj-decode'\n",
    "        )\n",
    "\n",
    "        skip_outputs = []\n",
    "        conv_inputs = [inputs]\n",
    "        for i, (dilation, filter_width) in enumerate(zip(self.dilations, self.filter_widths)):\n",
    "            dilated_conv = temporal_convolution_layer(\n",
    "                inputs=inputs,\n",
    "                output_units=2*self.residual_channels,\n",
    "                convolution_width=filter_width,\n",
    "                causal=True,\n",
    "                dilation_rate=[dilation],\n",
    "                scope='dilated-conv-decode-{}'.format(i)\n",
    "            )\n",
    "            conv_filter, conv_gate = tf.split(dilated_conv, 2, axis=2)\n",
    "            dilated_conv = tf.nn.tanh(conv_filter)*tf.nn.sigmoid(conv_gate)\n",
    "\n",
    "            outputs = time_distributed_dense_layer(\n",
    "                inputs=dilated_conv,\n",
    "                output_units=self.skip_channels + self.residual_channels,\n",
    "                scope='dilated-conv-proj-decode-{}'.format(i)\n",
    "            )\n",
    "            skips, residuals = tf.split(outputs, [self.skip_channels, self.residual_channels], axis=2)\n",
    "\n",
    "            inputs += residuals\n",
    "            conv_inputs.append(inputs)\n",
    "            skip_outputs.append(skips)\n",
    "\n",
    "        skip_outputs = tf.nn.relu(tf.concat(skip_outputs, axis=2))\n",
    "        h = time_distributed_dense_layer(skip_outputs, 128, scope='dense-decode-1', activation=tf.nn.relu)\n",
    "        y_hat = time_distributed_dense_layer(h, 1, scope='dense-decode-2')\n",
    "        return y_hat\n",
    "\n",
    "    def decode(self, x, conv_inputs, features):\n",
    "        batch_size = tf.shape(x)[0]\n",
    "\n",
    "        # initialize state tensor arrays\n",
    "        state_queues = []\n",
    "        for i, (conv_input, dilation) in enumerate(zip(conv_inputs, self.dilations)):\n",
    "            batch_idx = tf.range(batch_size)\n",
    "            batch_idx = tf.tile(tf.expand_dims(batch_idx, 1), (1, dilation))\n",
    "            batch_idx = tf.reshape(batch_idx, [-1])\n",
    "\n",
    "            queue_begin_time = self.encode_len - dilation - 1\n",
    "            temporal_idx = tf.expand_dims(queue_begin_time, 1) + tf.expand_dims(tf.range(dilation), 0)\n",
    "            temporal_idx = tf.reshape(temporal_idx, [-1])\n",
    "\n",
    "            idx = tf.stack([batch_idx, temporal_idx], axis=1)\n",
    "            slices = tf.reshape(tf.gather_nd(conv_input, idx), (batch_size, dilation, shape(conv_input, 2)))\n",
    "\n",
    "            layer_ta = tf.TensorArray(dtype=tf.float32, size=dilation + self.num_decode_steps)\n",
    "            layer_ta = layer_ta.unstack(tf.transpose(slices, (1, 0, 2)))\n",
    "            state_queues.append(layer_ta)\n",
    "\n",
    "        # initialize feature tensor array\n",
    "        features_ta = tf.TensorArray(dtype=tf.float32, size=self.num_decode_steps)\n",
    "        features_ta = features_ta.unstack(tf.transpose(features, (1, 0, 2)))\n",
    "\n",
    "        # initialize output tensor array\n",
    "        emit_ta = tf.TensorArray(size=self.num_decode_steps, dtype=tf.float32)\n",
    "\n",
    "        # initialize other loop vars\n",
    "        elements_finished = 0 >= self.decode_len\n",
    "        time = tf.constant(0, dtype=tf.int32)\n",
    "\n",
    "        # get initial x input\n",
    "        current_idx = tf.stack([tf.range(tf.shape(self.encode_len)[0]), self.encode_len - 1], axis=1)\n",
    "        initial_input = tf.gather_nd(x, current_idx)\n",
    "\n",
    "        def loop_fn(time, current_input, queues):\n",
    "            current_features = features_ta.read(time)\n",
    "            current_input = tf.concat([current_input, current_features], axis=1)\n",
    "\n",
    "            with tf.variable_scope('x-proj-decode', reuse=True):\n",
    "                w_x_proj = tf.get_variable('weights')\n",
    "                b_x_proj = tf.get_variable('biases')\n",
    "                x_proj = tf.nn.tanh(tf.matmul(current_input, w_x_proj) + b_x_proj)\n",
    "\n",
    "            skip_outputs, updated_queues = [], []\n",
    "            for i, (conv_input, queue, dilation) in enumerate(zip(conv_inputs, queues, self.dilations)):\n",
    "\n",
    "                state = queue.read(time)\n",
    "                with tf.variable_scope('dilated-conv-decode-{}'.format(i), reuse=True):\n",
    "                    w_conv = tf.get_variable('weights'.format(i))\n",
    "                    b_conv = tf.get_variable('biases'.format(i))\n",
    "                    dilated_conv = tf.matmul(state, w_conv[0, :, :]) + tf.matmul(x_proj, w_conv[1, :, :]) + b_conv\n",
    "                conv_filter, conv_gate = tf.split(dilated_conv, 2, axis=1)\n",
    "                dilated_conv = tf.nn.tanh(conv_filter)*tf.nn.sigmoid(conv_gate)\n",
    "\n",
    "                with tf.variable_scope('dilated-conv-proj-decode-{}'.format(i), reuse=True):\n",
    "                    w_proj = tf.get_variable('weights'.format(i))\n",
    "                    b_proj = tf.get_variable('biases'.format(i))\n",
    "                    concat_outputs = tf.matmul(dilated_conv, w_proj) + b_proj\n",
    "                skips, residuals = tf.split(concat_outputs, [self.skip_channels, self.residual_channels], axis=1)\n",
    "\n",
    "                x_proj += residuals\n",
    "                skip_outputs.append(skips)\n",
    "                updated_queues.append(queue.write(time + dilation, x_proj))\n",
    "\n",
    "            skip_outputs = tf.nn.relu(tf.concat(skip_outputs, axis=1))\n",
    "            with tf.variable_scope('dense-decode-1', reuse=True):\n",
    "                w_h = tf.get_variable('weights')\n",
    "                b_h = tf.get_variable('biases')\n",
    "                h = tf.nn.relu(tf.matmul(skip_outputs, w_h) + b_h)\n",
    "\n",
    "            with tf.variable_scope('dense-decode-2', reuse=True):\n",
    "                w_y = tf.get_variable('weights')\n",
    "                b_y = tf.get_variable('biases')\n",
    "                y_hat = tf.matmul(h, w_y) + b_y\n",
    "\n",
    "            elements_finished = (time >= self.decode_len)\n",
    "            finished = tf.reduce_all(elements_finished)\n",
    "\n",
    "            next_input = tf.cond(\n",
    "                finished,\n",
    "                lambda: tf.zeros([batch_size, 1], dtype=tf.float32),\n",
    "                lambda: y_hat\n",
    "            )\n",
    "            next_elements_finished = (time >= self.decode_len - 1)\n",
    "\n",
    "            return (next_elements_finished, next_input, updated_queues)\n",
    "\n",
    "        def condition(unused_time, elements_finished, *_):\n",
    "            return tf.logical_not(tf.reduce_all(elements_finished))\n",
    "\n",
    "        def body(time, elements_finished, emit_ta, *state_queues):\n",
    "            (next_finished, emit_output, state_queues) = loop_fn(time, initial_input, state_queues)\n",
    "\n",
    "            emit = tf.where(elements_finished, tf.zeros_like(emit_output), emit_output)\n",
    "            emit_ta = emit_ta.write(time, emit)\n",
    "\n",
    "            elements_finished = tf.logical_or(elements_finished, next_finished)\n",
    "            return [time + 1, elements_finished, emit_ta] + list(state_queues)\n",
    "\n",
    "        returned = tf.while_loop(\n",
    "            cond=condition,\n",
    "            body=body,\n",
    "            loop_vars=[time, elements_finished, emit_ta] + state_queues\n",
    "        )\n",
    "\n",
    "        outputs_ta = returned[2]\n",
    "        y_hat = tf.transpose(outputs_ta.stack(), (1, 0, 2))\n",
    "        return y_hat\n",
    "\n",
    "    def calculate_loss(self):\n",
    "        x = self.get_input_sequences()\n",
    "\n",
    "        y_hat_encode, conv_inputs = self.encode(x, features=self.encode_features)\n",
    "        self.initialize_decode_params(x, features=self.decode_features)\n",
    "        y_hat_decode = self.decode(y_hat_encode, conv_inputs, features=self.decode_features)\n",
    "        y_hat_decode = self.inverse_transform(tf.squeeze(y_hat_decode, 2))\n",
    "        y_hat_decode = tf.nn.relu(y_hat_decode)\n",
    "\n",
    "        self.labels = self.y_decode\n",
    "        self.preds = y_hat_decode\n",
    "        self.loss = sequence_smape(self.labels, self.preds, self.decode_len, self.is_nan_decode)\n",
    "\n",
    "        self.prediction_tensors = {\n",
    "            'priors': self.x_encode,\n",
    "            'labels': self.labels,\n",
    "            'preds': self.preds,\n",
    "            'page_id': self.page_id,\n",
    "        }\n",
    "\n",
    "        return self.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[01/31/2018 07:00:19 PM]] \n",
      "Network hyper-parameters:\n",
      "{'batch_size': 128,\n",
      " 'checkpoint_dir': './tf-data/checkpoints',\n",
      " 'dilations': [1,\n",
      "               2,\n",
      "               4,\n",
      "               8,\n",
      "               16,\n",
      "               32,\n",
      "               64,\n",
      "               128,\n",
      "               1,\n",
      "               2,\n",
      "               4,\n",
      "               8,\n",
      "               16,\n",
      "               32,\n",
      "               64,\n",
      "               128,\n",
      "               1,\n",
      "               2,\n",
      "               4,\n",
      "               8,\n",
      "               16,\n",
      "               32,\n",
      "               64,\n",
      "               128],\n",
      " 'early_stopping_steps': 500,\n",
      " 'enable_parameter_averaging': False,\n",
      " 'filter_widths': [2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2],\n",
      " 'grad_clip': 20,\n",
      " 'keep_prob_scalar': 1.0,\n",
      " 'learning_rate': 0.001,\n",
      " 'log_dir': './tf-data/logs',\n",
      " 'log_interval': 10,\n",
      " 'logger': <Logger cnn.2018-01-31.19-00-19.220766 (INFO)>,\n",
      " 'loss_averaging_window': 100,\n",
      " 'min_steps_to_checkpoint': 100,\n",
      " 'name': 'wave',\n",
      " 'num_decode_steps': 64,\n",
      " 'num_restarts': 2,\n",
      " 'num_training_steps': 20000,\n",
      " 'num_validation_batches': 1,\n",
      " 'optimizer': 'adam',\n",
      " 'prediction_dir': './tf-data/predictions',\n",
      " 'reader': <datareader_wave.DataReader object at 0x121ff4dd8>,\n",
      " 'regularization_constant': 0.0,\n",
      " 'residual_channels': 32,\n",
      " 'skip_channels': 32,\n",
      " 'warm_start_init_step': 0}\n",
      "[[01/31/2018 07:00:19 PM]] \n",
      "Data reader parameters:\n",
      "{'test_df': <dataframe.DataFrame object at 0x1188becf8>,\n",
      " 'train_df': <dataframe.DataFrame object at 0x1113d30f0>,\n",
      " 'val_df': <dataframe.DataFrame object at 0x122092160>}\n",
      "[[01/31/2018 07:00:19 PM]] \n",
      "[[01/31/2018 07:00:19 PM]] Data dimensions:\n",
      "[[01/31/2018 07:00:19 PM]] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/logging/__init__.py\", line 987, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/logging/__init__.py\", line 833, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/logging/__init__.py\", line 570, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/logging/__init__.py\", line 333, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 474, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/tornado/ioloop.py\", line 887, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-23b49b84d373>\", line 33, in <module>\n",
      "    nn = get_nn(reader)\n",
      "  File \"<ipython-input-4-23b49b84d373>\", line 26, in get_nn\n",
      "    name='wave',\n",
      "  File \"<ipython-input-3-ec1ac90d3f1b>\", line 17, in __init__\n",
      "    super(cnn, self).__init__(**kwargs)\n",
      "  File \"/Users/junxie/Dropbox/JuanCode/Insight/Project/forecaster/forecaster/tf_basemodel.py\", line 100, in __init__\n",
      "    self.reader.describe(self.logger)\n",
      "  File \"/Users/junxie/Dropbox/JuanCode/Insight/Project/forecaster/forecaster/datareader_wave.py\", line 28, in describe\n",
      "    logger.info('train size', len(self.train_df))\n",
      "Message: 'train size'\n",
      "Arguments: (13781,)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/logging/__init__.py\", line 987, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/logging/__init__.py\", line 833, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/logging/__init__.py\", line 570, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/logging/__init__.py\", line 333, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 474, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/tornado/ioloop.py\", line 887, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-23b49b84d373>\", line 33, in <module>\n",
      "    nn = get_nn(reader)\n",
      "  File \"<ipython-input-4-23b49b84d373>\", line 26, in get_nn\n",
      "    name='wave',\n",
      "  File \"<ipython-input-3-ec1ac90d3f1b>\", line 17, in __init__\n",
      "    super(cnn, self).__init__(**kwargs)\n",
      "  File \"/Users/junxie/Dropbox/JuanCode/Insight/Project/forecaster/forecaster/tf_basemodel.py\", line 100, in __init__\n",
      "    self.reader.describe(self.logger)\n",
      "  File \"/Users/junxie/Dropbox/JuanCode/Insight/Project/forecaster/forecaster/datareader_wave.py\", line 28, in describe\n",
      "    logger.info('train size', len(self.train_df))\n",
      "Message: 'train size'\n",
      "Arguments: (13781,)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/logging/__init__.py\", line 987, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/logging/__init__.py\", line 833, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/logging/__init__.py\", line 570, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/logging/__init__.py\", line 333, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 474, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/tornado/ioloop.py\", line 887, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-23b49b84d373>\", line 33, in <module>\n",
      "    nn = get_nn(reader)\n",
      "  File \"<ipython-input-4-23b49b84d373>\", line 26, in get_nn\n",
      "    name='wave',\n",
      "  File \"<ipython-input-3-ec1ac90d3f1b>\", line 17, in __init__\n",
      "    super(cnn, self).__init__(**kwargs)\n",
      "  File \"/Users/junxie/Dropbox/JuanCode/Insight/Project/forecaster/forecaster/tf_basemodel.py\", line 100, in __init__\n",
      "    self.reader.describe(self.logger)\n",
      "  File \"/Users/junxie/Dropbox/JuanCode/Insight/Project/forecaster/forecaster/datareader_wave.py\", line 29, in describe\n",
      "    logger.info('val size', len(self.val_df))\n",
      "Message: 'val size'\n",
      "Arguments: (726,)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/logging/__init__.py\", line 987, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/logging/__init__.py\", line 833, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/logging/__init__.py\", line 570, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/logging/__init__.py\", line 333, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 474, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/tornado/ioloop.py\", line 887, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-23b49b84d373>\", line 33, in <module>\n",
      "    nn = get_nn(reader)\n",
      "  File \"<ipython-input-4-23b49b84d373>\", line 26, in get_nn\n",
      "    name='wave',\n",
      "  File \"<ipython-input-3-ec1ac90d3f1b>\", line 17, in __init__\n",
      "    super(cnn, self).__init__(**kwargs)\n",
      "  File \"/Users/junxie/Dropbox/JuanCode/Insight/Project/forecaster/forecaster/tf_basemodel.py\", line 100, in __init__\n",
      "    self.reader.describe(self.logger)\n",
      "  File \"/Users/junxie/Dropbox/JuanCode/Insight/Project/forecaster/forecaster/datareader_wave.py\", line 29, in describe\n",
      "    logger.info('val size', len(self.val_df))\n",
      "Message: 'val size'\n",
      "Arguments: (726,)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/logging/__init__.py\", line 987, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/logging/__init__.py\", line 833, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/logging/__init__.py\", line 570, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/logging/__init__.py\", line 333, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 474, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/tornado/ioloop.py\", line 887, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-23b49b84d373>\", line 33, in <module>\n",
      "    nn = get_nn(reader)\n",
      "  File \"<ipython-input-4-23b49b84d373>\", line 26, in get_nn\n",
      "    name='wave',\n",
      "  File \"<ipython-input-3-ec1ac90d3f1b>\", line 17, in __init__\n",
      "    super(cnn, self).__init__(**kwargs)\n",
      "  File \"/Users/junxie/Dropbox/JuanCode/Insight/Project/forecaster/forecaster/tf_basemodel.py\", line 100, in __init__\n",
      "    self.reader.describe(self.logger)\n",
      "  File \"/Users/junxie/Dropbox/JuanCode/Insight/Project/forecaster/forecaster/datareader_wave.py\", line 30, in describe\n",
      "    logger.info('test size', len(self.test_df))\n",
      "Message: 'test size'\n",
      "Arguments: (14507,)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/logging/__init__.py\", line 987, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/logging/__init__.py\", line 833, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/logging/__init__.py\", line 570, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/logging/__init__.py\", line 333, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 474, in start\n",
      "    ioloop.IOLoop.instance().start()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/tornado/ioloop.py\", line 887, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/Users/junxie/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-23b49b84d373>\", line 33, in <module>\n",
      "    nn = get_nn(reader)\n",
      "  File \"<ipython-input-4-23b49b84d373>\", line 26, in get_nn\n",
      "    name='wave',\n",
      "  File \"<ipython-input-3-ec1ac90d3f1b>\", line 17, in __init__\n",
      "    super(cnn, self).__init__(**kwargs)\n",
      "  File \"/Users/junxie/Dropbox/JuanCode/Insight/Project/forecaster/forecaster/tf_basemodel.py\", line 100, in __init__\n",
      "    self.reader.describe(self.logger)\n",
      "  File \"/Users/junxie/Dropbox/JuanCode/Insight/Project/forecaster/forecaster/datareader_wave.py\", line 30, in describe\n",
      "    logger.info('test size', len(self.test_df))\n",
      "Message: 'test size'\n",
      "Arguments: (14507,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[01/31/2018 07:00:48 PM]] \n",
      "\n",
      "All parameters:\n",
      "[('Variable:0', []),\n",
      " ('Variable_1:0', []),\n",
      " ('x-proj-encode/weights:0', [18, 32]),\n",
      " ('x-proj-encode/biases:0', [32]),\n",
      " ('dilated-conv-encode-0/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-0/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-0/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-0/biases:0', [64]),\n",
      " ('dilated-conv-encode-1/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-1/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-1/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-1/biases:0', [64]),\n",
      " ('dilated-conv-encode-2/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-2/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-2/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-2/biases:0', [64]),\n",
      " ('dilated-conv-encode-3/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-3/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-3/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-3/biases:0', [64]),\n",
      " ('dilated-conv-encode-4/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-4/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-4/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-4/biases:0', [64]),\n",
      " ('dilated-conv-encode-5/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-5/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-5/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-5/biases:0', [64]),\n",
      " ('dilated-conv-encode-6/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-6/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-6/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-6/biases:0', [64]),\n",
      " ('dilated-conv-encode-7/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-7/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-7/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-7/biases:0', [64]),\n",
      " ('dilated-conv-encode-8/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-8/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-8/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-8/biases:0', [64]),\n",
      " ('dilated-conv-encode-9/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-9/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-9/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-9/biases:0', [64]),\n",
      " ('dilated-conv-encode-10/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-10/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-10/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-10/biases:0', [64]),\n",
      " ('dilated-conv-encode-11/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-11/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-11/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-11/biases:0', [64]),\n",
      " ('dilated-conv-encode-12/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-12/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-12/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-12/biases:0', [64]),\n",
      " ('dilated-conv-encode-13/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-13/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-13/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-13/biases:0', [64]),\n",
      " ('dilated-conv-encode-14/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-14/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-14/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-14/biases:0', [64]),\n",
      " ('dilated-conv-encode-15/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-15/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-15/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-15/biases:0', [64]),\n",
      " ('dilated-conv-encode-16/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-16/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-16/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-16/biases:0', [64]),\n",
      " ('dilated-conv-encode-17/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-17/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-17/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-17/biases:0', [64]),\n",
      " ('dilated-conv-encode-18/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-18/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-18/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-18/biases:0', [64]),\n",
      " ('dilated-conv-encode-19/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-19/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-19/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-19/biases:0', [64]),\n",
      " ('dilated-conv-encode-20/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-20/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-20/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-20/biases:0', [64]),\n",
      " ('dilated-conv-encode-21/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-21/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-21/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-21/biases:0', [64]),\n",
      " ('dilated-conv-encode-22/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-22/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-22/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-22/biases:0', [64]),\n",
      " ('dilated-conv-encode-23/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-23/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-23/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-23/biases:0', [64]),\n",
      " ('dense-encode-1/weights:0', [768, 128]),\n",
      " ('dense-encode-1/biases:0', [128]),\n",
      " ('dense-encode-2/weights:0', [128, 1]),\n",
      " ('dense-encode-2/biases:0', [1]),\n",
      " ('x-proj-decode/weights:0', [80, 32]),\n",
      " ('x-proj-decode/biases:0', [32]),\n",
      " ('dilated-conv-decode-0/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-0/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-0/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-0/biases:0', [64]),\n",
      " ('dilated-conv-decode-1/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-1/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-1/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-1/biases:0', [64]),\n",
      " ('dilated-conv-decode-2/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-2/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-2/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-2/biases:0', [64]),\n",
      " ('dilated-conv-decode-3/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-3/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-3/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-3/biases:0', [64]),\n",
      " ('dilated-conv-decode-4/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-4/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-4/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-4/biases:0', [64]),\n",
      " ('dilated-conv-decode-5/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-5/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-5/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-5/biases:0', [64]),\n",
      " ('dilated-conv-decode-6/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-6/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-6/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-6/biases:0', [64]),\n",
      " ('dilated-conv-decode-7/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-7/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-7/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-7/biases:0', [64]),\n",
      " ('dilated-conv-decode-8/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-8/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-8/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-8/biases:0', [64]),\n",
      " ('dilated-conv-decode-9/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-9/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-9/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-9/biases:0', [64]),\n",
      " ('dilated-conv-decode-10/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-10/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-10/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-10/biases:0', [64]),\n",
      " ('dilated-conv-decode-11/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-11/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-11/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-11/biases:0', [64]),\n",
      " ('dilated-conv-decode-12/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-12/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-12/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-12/biases:0', [64]),\n",
      " ('dilated-conv-decode-13/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-13/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-13/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-13/biases:0', [64]),\n",
      " ('dilated-conv-decode-14/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-14/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-14/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-14/biases:0', [64]),\n",
      " ('dilated-conv-decode-15/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-15/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-15/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-15/biases:0', [64]),\n",
      " ('dilated-conv-decode-16/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-16/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-16/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-16/biases:0', [64]),\n",
      " ('dilated-conv-decode-17/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-17/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-17/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-17/biases:0', [64]),\n",
      " ('dilated-conv-decode-18/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-18/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-18/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-18/biases:0', [64]),\n",
      " ('dilated-conv-decode-19/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-19/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-19/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-19/biases:0', [64]),\n",
      " ('dilated-conv-decode-20/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-20/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-20/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-20/biases:0', [64]),\n",
      " ('dilated-conv-decode-21/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-21/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-21/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-21/biases:0', [64]),\n",
      " ('dilated-conv-decode-22/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-22/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-22/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-22/biases:0', [64]),\n",
      " ('dilated-conv-decode-23/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-23/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-23/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-23/biases:0', [64]),\n",
      " ('dense-decode-1/weights:0', [768, 128]),\n",
      " ('dense-decode-1/biases:0', [128]),\n",
      " ('dense-decode-2/weights:0', [128, 1]),\n",
      " ('dense-decode-2/biases:0', [1]),\n",
      " ('Variable_2:0', []),\n",
      " ('Variable_3:0', []),\n",
      " ('beta1_power:0', []),\n",
      " ('beta2_power:0', []),\n",
      " ('x-proj-encode/weights/Adam:0', [18, 32]),\n",
      " ('x-proj-encode/weights/Adam_1:0', [18, 32]),\n",
      " ('x-proj-encode/biases/Adam:0', [32]),\n",
      " ('x-proj-encode/biases/Adam_1:0', [32]),\n",
      " ('dilated-conv-encode-0/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-0/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-0/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-0/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-0/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-0/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-0/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-0/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-1/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-1/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-1/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-1/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-1/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-1/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-1/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-1/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-2/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-2/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-2/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-2/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-2/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-2/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-2/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-2/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-3/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-3/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-3/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-3/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-3/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-3/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-3/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-3/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-4/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-4/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-4/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-4/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-4/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-4/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-4/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-4/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-5/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-5/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-5/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-5/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-5/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-5/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-5/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-5/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-6/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-6/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-6/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-6/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-6/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-6/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-6/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-6/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-7/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-7/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-7/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-7/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-7/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-7/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-7/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-7/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-8/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-8/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-8/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-8/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-8/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-8/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-8/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-8/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-9/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-9/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-9/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-9/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-9/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-9/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-9/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-9/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-10/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-10/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-10/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-10/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-10/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-10/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-10/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-10/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-11/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-11/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-11/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-11/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-11/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-11/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-11/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-11/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-12/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-12/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-12/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-12/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-12/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-12/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-12/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-12/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-13/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-13/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-13/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-13/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-13/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-13/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-13/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-13/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-14/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-14/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-14/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-14/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-14/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-14/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-14/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-14/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-15/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-15/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-15/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-15/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-15/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-15/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-15/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-15/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-16/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-16/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-16/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-16/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-16/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-16/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-16/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-16/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-17/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-17/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-17/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-17/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-17/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-17/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-17/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-17/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-18/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-18/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-18/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-18/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-18/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-18/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-18/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-18/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-19/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-19/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-19/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-19/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-19/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-19/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-19/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-19/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-20/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-20/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-20/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-20/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-20/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-20/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-20/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-20/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-21/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-21/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-21/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-21/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-21/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-21/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-21/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-21/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-22/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-22/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-22/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-22/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-22/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-22/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-22/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-22/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-23/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-23/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-23/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-23/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-23/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-23/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-23/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-23/biases/Adam_1:0', [64]),\n",
      " ('dense-encode-1/weights/Adam:0', [768, 128]),\n",
      " ('dense-encode-1/weights/Adam_1:0', [768, 128]),\n",
      " ('dense-encode-1/biases/Adam:0', [128]),\n",
      " ('dense-encode-1/biases/Adam_1:0', [128]),\n",
      " ('dense-encode-2/weights/Adam:0', [128, 1]),\n",
      " ('dense-encode-2/weights/Adam_1:0', [128, 1]),\n",
      " ('dense-encode-2/biases/Adam:0', [1]),\n",
      " ('dense-encode-2/biases/Adam_1:0', [1]),\n",
      " ('x-proj-decode/weights/Adam:0', [80, 32]),\n",
      " ('x-proj-decode/weights/Adam_1:0', [80, 32]),\n",
      " ('x-proj-decode/biases/Adam:0', [32]),\n",
      " ('x-proj-decode/biases/Adam_1:0', [32]),\n",
      " ('dilated-conv-decode-0/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-0/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-0/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-0/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-0/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-0/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-0/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-0/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-1/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-1/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-1/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-1/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-1/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-1/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-1/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-1/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-2/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-2/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-2/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-2/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-2/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-2/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-2/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-2/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-3/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-3/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-3/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-3/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-3/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-3/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-3/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-3/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-4/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-4/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-4/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-4/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-4/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-4/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-4/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-4/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-5/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-5/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-5/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-5/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-5/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-5/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-5/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-5/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-6/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-6/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-6/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-6/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-6/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-6/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-6/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-6/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-7/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-7/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-7/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-7/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-7/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-7/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-7/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-7/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-8/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-8/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-8/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-8/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-8/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-8/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-8/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-8/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-9/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-9/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-9/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-9/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-9/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-9/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-9/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-9/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-10/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-10/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-10/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-10/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-10/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-10/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-10/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-10/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-11/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-11/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-11/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-11/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-11/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-11/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-11/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-11/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-12/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-12/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-12/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-12/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-12/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-12/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-12/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-12/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-13/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-13/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-13/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-13/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-13/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-13/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-13/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-13/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-14/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-14/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-14/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-14/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-14/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-14/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-14/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-14/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-15/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-15/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-15/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-15/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-15/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-15/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-15/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-15/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-16/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-16/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-16/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-16/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-16/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-16/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-16/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-16/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-17/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-17/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-17/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-17/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-17/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-17/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-17/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-17/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-18/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-18/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-18/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-18/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-18/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-18/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-18/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-18/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-19/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-19/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-19/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-19/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-19/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-19/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-19/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-19/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-20/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-20/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-20/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-20/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-20/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-20/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-20/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-20/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-21/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-21/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-21/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-21/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-21/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-21/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-21/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-21/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-22/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-22/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-22/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-22/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-22/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-22/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-22/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-22/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-23/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-23/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-23/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-23/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-23/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-23/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-23/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-23/biases/Adam_1:0', [64]),\n",
      " ('dense-decode-1/weights/Adam:0', [768, 128]),\n",
      " ('dense-decode-1/weights/Adam_1:0', [768, 128]),\n",
      " ('dense-decode-1/biases/Adam:0', [128]),\n",
      " ('dense-decode-1/biases/Adam_1:0', [128]),\n",
      " ('dense-decode-2/weights/Adam:0', [128, 1]),\n",
      " ('dense-decode-2/weights/Adam_1:0', [128, 1]),\n",
      " ('dense-decode-2/biases/Adam:0', [1]),\n",
      " ('dense-decode-2/biases/Adam_1:0', [1])]\n",
      "Trainable parameters:\n",
      "[('x-proj-encode/weights:0', [18, 32]),\n",
      " ('x-proj-encode/biases:0', [32]),\n",
      " ('dilated-conv-encode-0/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-0/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-0/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-0/biases:0', [64]),\n",
      " ('dilated-conv-encode-1/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-1/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-1/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-1/biases:0', [64]),\n",
      " ('dilated-conv-encode-2/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-2/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-2/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-2/biases:0', [64]),\n",
      " ('dilated-conv-encode-3/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-3/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-3/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-3/biases:0', [64]),\n",
      " ('dilated-conv-encode-4/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-4/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-4/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-4/biases:0', [64]),\n",
      " ('dilated-conv-encode-5/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-5/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-5/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-5/biases:0', [64]),\n",
      " ('dilated-conv-encode-6/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-6/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-6/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-6/biases:0', [64]),\n",
      " ('dilated-conv-encode-7/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-7/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-7/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-7/biases:0', [64]),\n",
      " ('dilated-conv-encode-8/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-8/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-8/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-8/biases:0', [64]),\n",
      " ('dilated-conv-encode-9/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-9/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-9/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-9/biases:0', [64]),\n",
      " ('dilated-conv-encode-10/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-10/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-10/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-10/biases:0', [64]),\n",
      " ('dilated-conv-encode-11/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-11/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-11/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-11/biases:0', [64]),\n",
      " ('dilated-conv-encode-12/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-12/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-12/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-12/biases:0', [64]),\n",
      " ('dilated-conv-encode-13/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-13/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-13/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-13/biases:0', [64]),\n",
      " ('dilated-conv-encode-14/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-14/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-14/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-14/biases:0', [64]),\n",
      " ('dilated-conv-encode-15/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-15/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-15/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-15/biases:0', [64]),\n",
      " ('dilated-conv-encode-16/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-16/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-16/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-16/biases:0', [64]),\n",
      " ('dilated-conv-encode-17/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-17/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-17/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-17/biases:0', [64]),\n",
      " ('dilated-conv-encode-18/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-18/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-18/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-18/biases:0', [64]),\n",
      " ('dilated-conv-encode-19/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-19/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-19/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-19/biases:0', [64]),\n",
      " ('dilated-conv-encode-20/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-20/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-20/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-20/biases:0', [64]),\n",
      " ('dilated-conv-encode-21/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-21/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-21/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-21/biases:0', [64]),\n",
      " ('dilated-conv-encode-22/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-22/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-22/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-22/biases:0', [64]),\n",
      " ('dilated-conv-encode-23/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-23/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-23/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-23/biases:0', [64]),\n",
      " ('dense-encode-1/weights:0', [768, 128]),\n",
      " ('dense-encode-1/biases:0', [128]),\n",
      " ('dense-encode-2/weights:0', [128, 1]),\n",
      " ('dense-encode-2/biases:0', [1]),\n",
      " ('x-proj-decode/weights:0', [80, 32]),\n",
      " ('x-proj-decode/biases:0', [32]),\n",
      " ('dilated-conv-decode-0/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-0/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-0/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-0/biases:0', [64]),\n",
      " ('dilated-conv-decode-1/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-1/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-1/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-1/biases:0', [64]),\n",
      " ('dilated-conv-decode-2/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-2/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-2/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-2/biases:0', [64]),\n",
      " ('dilated-conv-decode-3/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-3/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-3/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-3/biases:0', [64]),\n",
      " ('dilated-conv-decode-4/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-4/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-4/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-4/biases:0', [64]),\n",
      " ('dilated-conv-decode-5/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-5/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-5/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-5/biases:0', [64]),\n",
      " ('dilated-conv-decode-6/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-6/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-6/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-6/biases:0', [64]),\n",
      " ('dilated-conv-decode-7/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-7/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-7/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-7/biases:0', [64]),\n",
      " ('dilated-conv-decode-8/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-8/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-8/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-8/biases:0', [64]),\n",
      " ('dilated-conv-decode-9/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-9/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-9/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-9/biases:0', [64]),\n",
      " ('dilated-conv-decode-10/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-10/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-10/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-10/biases:0', [64]),\n",
      " ('dilated-conv-decode-11/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-11/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-11/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-11/biases:0', [64]),\n",
      " ('dilated-conv-decode-12/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-12/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-12/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-12/biases:0', [64]),\n",
      " ('dilated-conv-decode-13/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-13/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-13/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-13/biases:0', [64]),\n",
      " ('dilated-conv-decode-14/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-14/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-14/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-14/biases:0', [64]),\n",
      " ('dilated-conv-decode-15/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-15/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-15/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-15/biases:0', [64]),\n",
      " ('dilated-conv-decode-16/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-16/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-16/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-16/biases:0', [64]),\n",
      " ('dilated-conv-decode-17/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-17/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-17/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-17/biases:0', [64]),\n",
      " ('dilated-conv-decode-18/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-18/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-18/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-18/biases:0', [64]),\n",
      " ('dilated-conv-decode-19/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-19/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-19/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-19/biases:0', [64]),\n",
      " ('dilated-conv-decode-20/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-20/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-20/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-20/biases:0', [64]),\n",
      " ('dilated-conv-decode-21/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-21/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-21/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-21/biases:0', [64]),\n",
      " ('dilated-conv-decode-22/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-22/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-22/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-22/biases:0', [64]),\n",
      " ('dilated-conv-decode-23/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-23/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-23/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-23/biases:0', [64]),\n",
      " ('dense-decode-1/weights:0', [768, 128]),\n",
      " ('dense-decode-1/biases:0', [128]),\n",
      " ('dense-decode-2/weights:0', [128, 1]),\n",
      " ('dense-decode-2/biases:0', [1])]\n",
      "Trainable parameter count: 501378\n",
      "\n",
      "built graph\n"
     ]
    }
   ],
   "source": [
    "def get_nn(reader):\n",
    "    return cnn(\n",
    "        reader=reader,\n",
    "        work_dir='./tf-data',\n",
    "#         checkpoint_dir=os.path.join('./tf-data', 'checkpoints'),\n",
    "#         prediction_dir=os.path.join('./tf-data', 'predictions'),\n",
    "        optimizer='adam',\n",
    "        learning_rate=.001,\n",
    "        batch_size=128,\n",
    "        num_training_steps=20000,#200000\n",
    "        early_stopping_steps=500,#5000\n",
    "        warm_start_init_step=0,\n",
    "        regularization_constant=0.0,\n",
    "        keep_prob=1.0,\n",
    "        enable_parameter_averaging=False,\n",
    "        num_restarts=2,\n",
    "        min_steps_to_checkpoint=100,#500\n",
    "        log_interval=10,\n",
    "        num_validation_batches=1,\n",
    "        grad_clip=20,\n",
    "        residual_channels=32,\n",
    "        skip_channels=32,\n",
    "        dilations=[2**i for i in range(8)]*3,\n",
    "        filter_widths=[2 for i in range(8)]*3,\n",
    "        num_decode_steps=64,\n",
    "        name='wave',\n",
    "    )\n",
    "\n",
    "reader = DataReader(\n",
    "    data_dir=os.path.join(root, 'processed/')\n",
    ")\n",
    "\n",
    "nn = get_nn(reader)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start at: 2018-01-23.21-38-53.486037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[[step        0]]     [[train]]     loss: 0.5801267        [[val]]     loss: 0.58279985       \n",
      "[[step       10]]     [[train]]     loss: 0.59160571       [[val]]     loss: 0.58986149       \n",
      "[[step       20]]     [[train]]     loss: 0.58218832       [[val]]     loss: 0.57497193       \n",
      "[[step       30]]     [[train]]     loss: 0.57649951       [[val]]     loss: 0.56725828       \n",
      "[[step       40]]     [[train]]     loss: 0.56500178       [[val]]     loss: 0.55407994       \n",
      "[[step       50]]     [[train]]     loss: 0.54982256       [[val]]     loss: 0.54225223       \n",
      "[[step       60]]     [[train]]     loss: 0.53550219       [[val]]     loss: 0.53244147       \n",
      "[[step       70]]     [[train]]     loss: 0.52761102       [[val]]     loss: 0.52411054       \n",
      "[[step       80]]     [[train]]     loss: 0.51864632       [[val]]     loss: 0.51614727       \n",
      "[[step       90]]     [[train]]     loss: 0.51106744       [[val]]     loss: 0.50802393       \n",
      "[[step      100]]     [[train]]     loss: 0.50530026       [[val]]     loss: 0.50180048       \n",
      "[[step      110]]     [[train]]     loss: 0.49212302       [[val]]     loss: 0.48831635       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      120]]     [[train]]     loss: 0.47877758       [[val]]     loss: 0.47666617       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      130]]     [[train]]     loss: 0.46786487       [[val]]     loss: 0.46565828       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      140]]     [[train]]     loss: 0.4588961        [[val]]     loss: 0.4586927        \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      150]]     [[train]]     loss: 0.4539686        [[val]]     loss: 0.45373934       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      160]]     [[train]]     loss: 0.45084696       [[val]]     loss: 0.45010718       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      170]]     [[train]]     loss: 0.4471064        [[val]]     loss: 0.44558472       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      180]]     [[train]]     loss: 0.44558725       [[val]]     loss: 0.44272623       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      190]]     [[train]]     loss: 0.44277075       [[val]]     loss: 0.4412207        \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      200]]     [[train]]     loss: 0.44089193       [[val]]     loss: 0.43919933       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      210]]     [[train]]     loss: 0.43933029       [[val]]     loss: 0.43607278       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      220]]     [[train]]     loss: 0.43870817       [[val]]     loss: 0.43548997       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      230]]     [[train]]     loss: 0.43671506       [[val]]     loss: 0.43406769       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      240]]     [[train]]     loss: 0.43600617       [[val]]     loss: 0.43121598       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      250]]     [[train]]     loss: 0.43451077       [[val]]     loss: 0.42894986       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      260]]     [[train]]     loss: 0.43324564       [[val]]     loss: 0.42621923       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      270]]     [[train]]     loss: 0.43188065       [[val]]     loss: 0.42591762       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      280]]     [[train]]     loss: 0.43022446       [[val]]     loss: 0.4243186        \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      290]]     [[train]]     loss: 0.4303582        [[val]]     loss: 0.42349907       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      300]]     [[train]]     loss: 0.42945623       [[val]]     loss: 0.42152296       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      310]]     [[train]]     loss: 0.42847849       [[val]]     loss: 0.42092636       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      320]]     [[train]]     loss: 0.42727886       [[val]]     loss: 0.41945136       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      330]]     [[train]]     loss: 0.42644044       [[val]]     loss: 0.41803131       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      340]]     [[train]]     loss: 0.4264609        [[val]]     loss: 0.41899675       \n",
      "[[step      350]]     [[train]]     loss: 0.42608338       [[val]]     loss: 0.41839069       \n",
      "[[step      360]]     [[train]]     loss: 0.4257449        [[val]]     loss: 0.41793339       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      370]]     [[train]]     loss: 0.42497699       [[val]]     loss: 0.41674474       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      380]]     [[train]]     loss: 0.42525225       [[val]]     loss: 0.41632802       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      390]]     [[train]]     loss: 0.42447779       [[val]]     loss: 0.41591621       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      400]]     [[train]]     loss: 0.42349105       [[val]]     loss: 0.41443781       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      410]]     [[train]]     loss: 0.42197986       [[val]]     loss: 0.41438824       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      420]]     [[train]]     loss: 0.42228007       [[val]]     loss: 0.41366505       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      430]]     [[train]]     loss: 0.42242766       [[val]]     loss: 0.41429752       \n",
      "[[step      440]]     [[train]]     loss: 0.42075043       [[val]]     loss: 0.41450983       \n",
      "[[step      450]]     [[train]]     loss: 0.42138101       [[val]]     loss: 0.41493752       \n",
      "[[step      460]]     [[train]]     loss: 0.42078795       [[val]]     loss: 0.41513063       \n",
      "[[step      470]]     [[train]]     loss: 0.41943229       [[val]]     loss: 0.41392773       \n",
      "[[step      480]]     [[train]]     loss: 0.41852212       [[val]]     loss: 0.41512317       \n",
      "[[step      490]]     [[train]]     loss: 0.41879505       [[val]]     loss: 0.41338234       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      500]]     [[train]]     loss: 0.41733382       [[val]]     loss: 0.4143751        \n",
      "[[step      510]]     [[train]]     loss: 0.41802818       [[val]]     loss: 0.41369976       \n",
      "[[step      520]]     [[train]]     loss: 0.41804835       [[val]]     loss: 0.41308253       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      530]]     [[train]]     loss: 0.41682845       [[val]]     loss: 0.41262348       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      540]]     [[train]]     loss: 0.41766258       [[val]]     loss: 0.41147768       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      550]]     [[train]]     loss: 0.41792771       [[val]]     loss: 0.41013826       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      560]]     [[train]]     loss: 0.41877772       [[val]]     loss: 0.40974313       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      570]]     [[train]]     loss: 0.41989793       [[val]]     loss: 0.41156563       \n",
      "[[step      580]]     [[train]]     loss: 0.41879977       [[val]]     loss: 0.40952734       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      590]]     [[train]]     loss: 0.41888458       [[val]]     loss: 0.41078898       \n",
      "[[step      600]]     [[train]]     loss: 0.42036686       [[val]]     loss: 0.41141477       \n",
      "[[step      610]]     [[train]]     loss: 0.41842129       [[val]]     loss: 0.41060526       \n",
      "[[step      620]]     [[train]]     loss: 0.41718749       [[val]]     loss: 0.41076376       \n",
      "[[step      630]]     [[train]]     loss: 0.41684492       [[val]]     loss: 0.41033065       \n",
      "[[step      640]]     [[train]]     loss: 0.41568152       [[val]]     loss: 0.40988602       \n",
      "[[step      650]]     [[train]]     loss: 0.41366543       [[val]]     loss: 0.40998145       \n",
      "[[step      660]]     [[train]]     loss: 0.41287128       [[val]]     loss: 0.40879672       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      670]]     [[train]]     loss: 0.41201101       [[val]]     loss: 0.40803895       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      680]]     [[train]]     loss: 0.41292597       [[val]]     loss: 0.40973706       \n",
      "[[step      690]]     [[train]]     loss: 0.41257279       [[val]]     loss: 0.40908413       \n",
      "[[step      700]]     [[train]]     loss: 0.41333181       [[val]]     loss: 0.40782494       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      710]]     [[train]]     loss: 0.41388938       [[val]]     loss: 0.4084172        \n",
      "[[step      720]]     [[train]]     loss: 0.41371687       [[val]]     loss: 0.40862027       \n",
      "[[step      730]]     [[train]]     loss: 0.41340333       [[val]]     loss: 0.40909901       \n",
      "[[step      740]]     [[train]]     loss: 0.41230188       [[val]]     loss: 0.40891361       \n",
      "[[step      750]]     [[train]]     loss: 0.41132079       [[val]]     loss: 0.40805527       \n",
      "[[step      760]]     [[train]]     loss: 0.41016861       [[val]]     loss: 0.40835989       \n",
      "[[step      770]]     [[train]]     loss: 0.40974506       [[val]]     loss: 0.40616489       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      780]]     [[train]]     loss: 0.40903929       [[val]]     loss: 0.40497434       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      790]]     [[train]]     loss: 0.4075856        [[val]]     loss: 0.40515766       \n",
      "[[step      800]]     [[train]]     loss: 0.40479174       [[val]]     loss: 0.40390227       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      810]]     [[train]]     loss: 0.40391073       [[val]]     loss: 0.40324042       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      820]]     [[train]]     loss: 0.40384458       [[val]]     loss: 0.4028077        \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      830]]     [[train]]     loss: 0.4028139        [[val]]     loss: 0.40123012       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      840]]     [[train]]     loss: 0.40462591       [[val]]     loss: 0.400357         \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      850]]     [[train]]     loss: 0.40565607       [[val]]     loss: 0.4015594        \n",
      "[[step      860]]     [[train]]     loss: 0.40573018       [[val]]     loss: 0.40108817       \n",
      "[[step      870]]     [[train]]     loss: 0.40691028       [[val]]     loss: 0.40166653       \n",
      "[[step      880]]     [[train]]     loss: 0.40643033       [[val]]     loss: 0.40036733       \n",
      "[[step      890]]     [[train]]     loss: 0.40685156       [[val]]     loss: 0.40054647       \n",
      "[[step      900]]     [[train]]     loss: 0.40635501       [[val]]     loss: 0.40141443       \n",
      "[[step      910]]     [[train]]     loss: 0.40579292       [[val]]     loss: 0.40171829       \n",
      "[[step      920]]     [[train]]     loss: 0.40674557       [[val]]     loss: 0.40099393       \n",
      "[[step      930]]     [[train]]     loss: 0.40777295       [[val]]     loss: 0.40102732       \n",
      "[[step      940]]     [[train]]     loss: 0.40707142       [[val]]     loss: 0.40054626       \n",
      "[[step      950]]     [[train]]     loss: 0.40642428       [[val]]     loss: 0.39988051       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      960]]     [[train]]     loss: 0.40682074       [[val]]     loss: 0.39955425       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step      970]]     [[train]]     loss: 0.4057291        [[val]]     loss: 0.40026003       \n",
      "[[step      980]]     [[train]]     loss: 0.40604434       [[val]]     loss: 0.40191271       \n",
      "[[step      990]]     [[train]]     loss: 0.40543558       [[val]]     loss: 0.40111949       \n",
      "[[step     1000]]     [[train]]     loss: 0.40601714       [[val]]     loss: 0.40095428       \n",
      "[[step     1010]]     [[train]]     loss: 0.40568677       [[val]]     loss: 0.40022747       \n",
      "[[step     1020]]     [[train]]     loss: 0.4044751        [[val]]     loss: 0.39938801       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step     1030]]     [[train]]     loss: 0.40239792       [[val]]     loss: 0.39874548       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step     1040]]     [[train]]     loss: 0.40071514       [[val]]     loss: 0.39859509       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step     1050]]     [[train]]     loss: 0.40125713       [[val]]     loss: 0.39797924       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step     1060]]     [[train]]     loss: 0.40057234       [[val]]     loss: 0.39852625       \n",
      "[[step     1070]]     [[train]]     loss: 0.40043556       [[val]]     loss: 0.39825816       \n",
      "[[step     1080]]     [[train]]     loss: 0.40002681       [[val]]     loss: 0.39685385       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step     1090]]     [[train]]     loss: 0.39935682       [[val]]     loss: 0.39554376       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step     1100]]     [[train]]     loss: 0.39913713       [[val]]     loss: 0.39501391       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step     1110]]     [[train]]     loss: 0.40085528       [[val]]     loss: 0.39485593       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step     1120]]     [[train]]     loss: 0.4013037        [[val]]     loss: 0.39560273       \n",
      "[[step     1130]]     [[train]]     loss: 0.40295847       [[val]]     loss: 0.39695777       \n",
      "[[step     1140]]     [[train]]     loss: 0.40319472       [[val]]     loss: 0.39741645       \n",
      "[[step     1150]]     [[train]]     loss: 0.40160102       [[val]]     loss: 0.39658366       \n",
      "[[step     1160]]     [[train]]     loss: 0.40298705       [[val]]     loss: 0.39651103       \n",
      "[[step     1170]]     [[train]]     loss: 0.40258554       [[val]]     loss: 0.39635          \n",
      "[[step     1180]]     [[train]]     loss: 0.40207371       [[val]]     loss: 0.39569494       \n",
      "[[step     1190]]     [[train]]     loss: 0.40194802       [[val]]     loss: 0.39696411       \n",
      "[[step     1200]]     [[train]]     loss: 0.40131741       [[val]]     loss: 0.39706823       \n",
      "[[step     1210]]     [[train]]     loss: 0.40090878       [[val]]     loss: 0.39690953       \n",
      "[[step     1220]]     [[train]]     loss: 0.40001266       [[val]]     loss: 0.3963535        \n",
      "[[step     1230]]     [[train]]     loss: 0.39961272       [[val]]     loss: 0.39497887       \n",
      "[[step     1240]]     [[train]]     loss: 0.40005935       [[val]]     loss: 0.39379139       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step     1250]]     [[train]]     loss: 0.40083366       [[val]]     loss: 0.39416407       \n",
      "[[step     1260]]     [[train]]     loss: 0.39854186       [[val]]     loss: 0.3935169        \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step     1270]]     [[train]]     loss: 0.39791115       [[val]]     loss: 0.39311061       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step     1280]]     [[train]]     loss: 0.39910125       [[val]]     loss: 0.39462341       \n",
      "[[step     1290]]     [[train]]     loss: 0.39993178       [[val]]     loss: 0.39305063       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step     1300]]     [[train]]     loss: 0.40013143       [[val]]     loss: 0.39327554       \n",
      "[[step     1310]]     [[train]]     loss: 0.39857536       [[val]]     loss: 0.39326234       \n",
      "[[step     1320]]     [[train]]     loss: 0.39729171       [[val]]     loss: 0.39329636       \n",
      "[[step     1330]]     [[train]]     loss: 0.39730868       [[val]]     loss: 0.39369098       \n",
      "[[step     1340]]     [[train]]     loss: 0.39747378       [[val]]     loss: 0.39432785       \n",
      "[[step     1350]]     [[train]]     loss: 0.3986302        [[val]]     loss: 0.39379806       \n",
      "[[step     1360]]     [[train]]     loss: 0.39962655       [[val]]     loss: 0.39368982       \n",
      "[[step     1370]]     [[train]]     loss: 0.39988357       [[val]]     loss: 0.3930783        \n",
      "[[step     1380]]     [[train]]     loss: 0.39931793       [[val]]     loss: 0.39219356       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step     1390]]     [[train]]     loss: 0.39901712       [[val]]     loss: 0.39387146       \n",
      "[[step     1400]]     [[train]]     loss: 0.39856548       [[val]]     loss: 0.39422103       \n",
      "[[step     1410]]     [[train]]     loss: 0.39840961       [[val]]     loss: 0.39413753       \n",
      "[[step     1420]]     [[train]]     loss: 0.39921441       [[val]]     loss: 0.39360161       \n",
      "[[step     1430]]     [[train]]     loss: 0.39862868       [[val]]     loss: 0.39369134       \n",
      "[[step     1440]]     [[train]]     loss: 0.39804407       [[val]]     loss: 0.39378233       \n",
      "[[step     1450]]     [[train]]     loss: 0.39683785       [[val]]     loss: 0.39303228       \n",
      "[[step     1460]]     [[train]]     loss: 0.39791951       [[val]]     loss: 0.39306796       \n",
      "[[step     1470]]     [[train]]     loss: 0.39745888       [[val]]     loss: 0.39290206       \n",
      "[[step     1480]]     [[train]]     loss: 0.39619611       [[val]]     loss: 0.39230896       \n",
      "[[step     1490]]     [[train]]     loss: 0.39429318       [[val]]     loss: 0.39098767       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step     1500]]     [[train]]     loss: 0.39484925       [[val]]     loss: 0.39055096       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step     1510]]     [[train]]     loss: 0.39473164       [[val]]     loss: 0.39068227       \n",
      "[[step     1520]]     [[train]]     loss: 0.39533307       [[val]]     loss: 0.39157623       \n",
      "[[step     1530]]     [[train]]     loss: 0.39607012       [[val]]     loss: 0.39088622       \n",
      "[[step     1540]]     [[train]]     loss: 0.39443222       [[val]]     loss: 0.39068119       \n",
      "[[step     1550]]     [[train]]     loss: 0.39387732       [[val]]     loss: 0.39152693       \n",
      "[[step     1560]]     [[train]]     loss: 0.39357326       [[val]]     loss: 0.39043629       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step     1570]]     [[train]]     loss: 0.39285032       [[val]]     loss: 0.3911558        \n",
      "[[step     1580]]     [[train]]     loss: 0.39297557       [[val]]     loss: 0.3916412        \n",
      "[[step     1590]]     [[train]]     loss: 0.39589743       [[val]]     loss: 0.39267889       \n",
      "[[step     1600]]     [[train]]     loss: 0.39508315       [[val]]     loss: 0.39252159       \n",
      "[[step     1610]]     [[train]]     loss: 0.39661413       [[val]]     loss: 0.39173183       \n",
      "[[step     1620]]     [[train]]     loss: 0.39688535       [[val]]     loss: 0.39057298       \n",
      "[[step     1630]]     [[train]]     loss: 0.39591978       [[val]]     loss: 0.39079771       \n",
      "[[step     1640]]     [[train]]     loss: 0.39714972       [[val]]     loss: 0.39091316       \n",
      "[[step     1650]]     [[train]]     loss: 0.39766795       [[val]]     loss: 0.39174385       \n",
      "[[step     1660]]     [[train]]     loss: 0.39651476       [[val]]     loss: 0.39258253       \n",
      "[[step     1670]]     [[train]]     loss: 0.39766198       [[val]]     loss: 0.39356268       \n",
      "[[step     1680]]     [[train]]     loss: 0.39818749       [[val]]     loss: 0.39268173       \n",
      "[[step     1690]]     [[train]]     loss: 0.39650073       [[val]]     loss: 0.39229783       \n",
      "[[step     1700]]     [[train]]     loss: 0.39697624       [[val]]     loss: 0.39158793       \n",
      "[[step     1710]]     [[train]]     loss: 0.39718769       [[val]]     loss: 0.39229014       \n",
      "[[step     1720]]     [[train]]     loss: 0.39697564       [[val]]     loss: 0.39225808       \n",
      "[[step     1730]]     [[train]]     loss: 0.39838165       [[val]]     loss: 0.39142491       \n",
      "[[step     1740]]     [[train]]     loss: 0.39801732       [[val]]     loss: 0.3911044        \n",
      "[[step     1750]]     [[train]]     loss: 0.39736854       [[val]]     loss: 0.39105404       \n",
      "[[step     1760]]     [[train]]     loss: 0.39595986       [[val]]     loss: 0.3912435        \n",
      "[[step     1770]]     [[train]]     loss: 0.39588918       [[val]]     loss: 0.3904469        \n",
      "[[step     1780]]     [[train]]     loss: 0.39616359       [[val]]     loss: 0.39160579       \n",
      "[[step     1790]]     [[train]]     loss: 0.39716235       [[val]]     loss: 0.39154365       \n",
      "[[step     1800]]     [[train]]     loss: 0.39798196       [[val]]     loss: 0.39274237       \n",
      "[[step     1810]]     [[train]]     loss: 0.39685048       [[val]]     loss: 0.39284885       \n",
      "[[step     1820]]     [[train]]     loss: 0.39663688       [[val]]     loss: 0.39375396       \n",
      "[[step     1830]]     [[train]]     loss: 0.39569617       [[val]]     loss: 0.39460912       \n",
      "[[step     1840]]     [[train]]     loss: 0.39696339       [[val]]     loss: 0.39507836       \n",
      "[[step     1850]]     [[train]]     loss: 0.39763597       [[val]]     loss: 0.39583384       \n",
      "[[step     1860]]     [[train]]     loss: 0.39905356       [[val]]     loss: 0.39491381       \n",
      "[[step     1870]]     [[train]]     loss: 0.39862881       [[val]]     loss: 0.3944572        \n",
      "[[step     1880]]     [[train]]     loss: 0.39857475       [[val]]     loss: 0.39311179       \n",
      "[[step     1890]]     [[train]]     loss: 0.39833799       [[val]]     loss: 0.39301506       \n",
      "[[step     1900]]     [[train]]     loss: 0.39774767       [[val]]     loss: 0.39253753       \n",
      "[[step     1910]]     [[train]]     loss: 0.39645858       [[val]]     loss: 0.39214328       \n",
      "[[step     1920]]     [[train]]     loss: 0.39490919       [[val]]     loss: 0.39209805       \n",
      "[[step     1930]]     [[train]]     loss: 0.39474555       [[val]]     loss: 0.39131986       \n",
      "[[step     1940]]     [[train]]     loss: 0.39385741       [[val]]     loss: 0.39079161       \n",
      "[[step     1950]]     [[train]]     loss: 0.39380023       [[val]]     loss: 0.38891079       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step     1960]]     [[train]]     loss: 0.39315942       [[val]]     loss: 0.38950391       \n",
      "[[step     1970]]     [[train]]     loss: 0.39404544       [[val]]     loss: 0.38997121       \n",
      "[[step     1980]]     [[train]]     loss: 0.39353766       [[val]]     loss: 0.38993089       \n",
      "[[step     1990]]     [[train]]     loss: 0.39272366       [[val]]     loss: 0.38958619       \n",
      "[[step     2000]]     [[train]]     loss: 0.39259725       [[val]]     loss: 0.38964128       \n",
      "[[step     2010]]     [[train]]     loss: 0.39550029       [[val]]     loss: 0.38942876       \n",
      "[[step     2020]]     [[train]]     loss: 0.39751509       [[val]]     loss: 0.39044809       \n",
      "[[step     2030]]     [[train]]     loss: 0.39678401       [[val]]     loss: 0.39036694       \n",
      "[[step     2040]]     [[train]]     loss: 0.3971392        [[val]]     loss: 0.38955888       \n",
      "[[step     2050]]     [[train]]     loss: 0.39665912       [[val]]     loss: 0.3889648        \n",
      "[[step     2060]]     [[train]]     loss: 0.39664303       [[val]]     loss: 0.38887294       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step     2070]]     [[train]]     loss: 0.39511765       [[val]]     loss: 0.38797832       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step     2080]]     [[train]]     loss: 0.3958379        [[val]]     loss: 0.388199         \n",
      "[[step     2090]]     [[train]]     loss: 0.39546153       [[val]]     loss: 0.3878523        \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step     2100]]     [[train]]     loss: 0.39418396       [[val]]     loss: 0.3870607        \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step     2110]]     [[train]]     loss: 0.39238974       [[val]]     loss: 0.38662566       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step     2120]]     [[train]]     loss: 0.39027839       [[val]]     loss: 0.38404121       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step     2130]]     [[train]]     loss: 0.39083693       [[val]]     loss: 0.38405912       \n",
      "[[step     2140]]     [[train]]     loss: 0.39086987       [[val]]     loss: 0.38479646       \n",
      "[[step     2150]]     [[train]]     loss: 0.38973339       [[val]]     loss: 0.38590629       \n",
      "[[step     2160]]     [[train]]     loss: 0.39069584       [[val]]     loss: 0.3854371        \n",
      "[[step     2170]]     [[train]]     loss: 0.39024339       [[val]]     loss: 0.38652715       \n",
      "[[step     2180]]     [[train]]     loss: 0.38954763       [[val]]     loss: 0.38626765       \n",
      "[[step     2190]]     [[train]]     loss: 0.39060958       [[val]]     loss: 0.38689285       \n",
      "[[step     2200]]     [[train]]     loss: 0.39191965       [[val]]     loss: 0.38675678       \n",
      "[[step     2210]]     [[train]]     loss: 0.39157446       [[val]]     loss: 0.38807335       \n",
      "[[step     2220]]     [[train]]     loss: 0.39219133       [[val]]     loss: 0.38799484       \n",
      "[[step     2230]]     [[train]]     loss: 0.39122641       [[val]]     loss: 0.38839981       \n",
      "[[step     2240]]     [[train]]     loss: 0.38971822       [[val]]     loss: 0.38798814       \n",
      "[[step     2250]]     [[train]]     loss: 0.39232229       [[val]]     loss: 0.38804323       \n",
      "[[step     2260]]     [[train]]     loss: 0.39260039       [[val]]     loss: 0.38938311       \n",
      "[[step     2270]]     [[train]]     loss: 0.39242531       [[val]]     loss: 0.3884308        \n",
      "[[step     2280]]     [[train]]     loss: 0.39251251       [[val]]     loss: 0.38943658       \n",
      "[[step     2290]]     [[train]]     loss: 0.39210685       [[val]]     loss: 0.38847889       \n",
      "[[step     2300]]     [[train]]     loss: 0.39200032       [[val]]     loss: 0.39005196       \n",
      "[[step     2310]]     [[train]]     loss: 0.39183089       [[val]]     loss: 0.38938281       \n",
      "[[step     2320]]     [[train]]     loss: 0.39460119       [[val]]     loss: 0.3906321        \n",
      "[[step     2330]]     [[train]]     loss: 0.39471494       [[val]]     loss: 0.39103777       \n",
      "[[step     2340]]     [[train]]     loss: 0.39570719       [[val]]     loss: 0.3911732        \n",
      "[[step     2350]]     [[train]]     loss: 0.39416091       [[val]]     loss: 0.39063912       \n",
      "[[step     2360]]     [[train]]     loss: 0.39287012       [[val]]     loss: 0.3901729        \n",
      "[[step     2370]]     [[train]]     loss: 0.39402577       [[val]]     loss: 0.38960605       \n",
      "[[step     2380]]     [[train]]     loss: 0.39393311       [[val]]     loss: 0.38920376       \n",
      "[[step     2390]]     [[train]]     loss: 0.39470261       [[val]]     loss: 0.39007076       \n",
      "[[step     2400]]     [[train]]     loss: 0.39556909       [[val]]     loss: 0.38882105       \n",
      "[[step     2410]]     [[train]]     loss: 0.39525687       [[val]]     loss: 0.38799524       \n",
      "[[step     2420]]     [[train]]     loss: 0.39327877       [[val]]     loss: 0.3875321        \n",
      "[[step     2430]]     [[train]]     loss: 0.39313345       [[val]]     loss: 0.38619861       \n",
      "[[step     2440]]     [[train]]     loss: 0.39303446       [[val]]     loss: 0.38672375       \n",
      "[[step     2450]]     [[train]]     loss: 0.39221404       [[val]]     loss: 0.38647469       \n",
      "[[step     2460]]     [[train]]     loss: 0.39265877       [[val]]     loss: 0.38565349       \n",
      "[[step     2470]]     [[train]]     loss: 0.39225892       [[val]]     loss: 0.3852272        \n",
      "[[step     2480]]     [[train]]     loss: 0.39360612       [[val]]     loss: 0.38476522       \n",
      "[[step     2490]]     [[train]]     loss: 0.39300585       [[val]]     loss: 0.38533334       \n",
      "[[step     2500]]     [[train]]     loss: 0.39259456       [[val]]     loss: 0.38497821       \n",
      "[[step     2510]]     [[train]]     loss: 0.39255414       [[val]]     loss: 0.38523181       \n",
      "[[step     2520]]     [[train]]     loss: 0.39235389       [[val]]     loss: 0.38519923       \n",
      "[[step     2530]]     [[train]]     loss: 0.39316236       [[val]]     loss: 0.38683397       \n",
      "[[step     2540]]     [[train]]     loss: 0.39112874       [[val]]     loss: 0.38580062       \n",
      "[[step     2550]]     [[train]]     loss: 0.39089624       [[val]]     loss: 0.38578444       \n",
      "[[step     2560]]     [[train]]     loss: 0.39122403       [[val]]     loss: 0.38605495       \n",
      "[[step     2570]]     [[train]]     loss: 0.39091228       [[val]]     loss: 0.38812391       \n",
      "[[step     2580]]     [[train]]     loss: 0.38957923       [[val]]     loss: 0.38813606       \n",
      "[[step     2590]]     [[train]]     loss: 0.38834033       [[val]]     loss: 0.38732167       \n",
      "[[step     2600]]     [[train]]     loss: 0.38698694       [[val]]     loss: 0.3877234        \n",
      "[[step     2610]]     [[train]]     loss: 0.38705496       [[val]]     loss: 0.38701028       \n",
      "[[step     2620]]     [[train]]     loss: 0.38560171       [[val]]     loss: 0.38608588       \n",
      "[[step     2630]]     [[train]]     loss: 0.38556454       [[val]]     loss: 0.38427428       \n",
      "restoring model from ./tf-data/checkpoints/model-2120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tf-data/checkpoints/model-2120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "halving learning rate\n",
      "[[step     2130]]     [[train]]     loss: 0.38628852       [[val]]     loss: 0.38454723       \n",
      "[[step     2140]]     [[train]]     loss: 0.38660409       [[val]]     loss: 0.38537622       \n",
      "[[step     2150]]     [[train]]     loss: 0.38673066       [[val]]     loss: 0.38547195       \n",
      "[[step     2160]]     [[train]]     loss: 0.38905879       [[val]]     loss: 0.38342705       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step     2170]]     [[train]]     loss: 0.38856491       [[val]]     loss: 0.38355135       \n",
      "[[step     2180]]     [[train]]     loss: 0.39001562       [[val]]     loss: 0.38267936       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step     2190]]     [[train]]     loss: 0.38986086       [[val]]     loss: 0.38258647       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step     2200]]     [[train]]     loss: 0.39010046       [[val]]     loss: 0.38383817       \n",
      "[[step     2210]]     [[train]]     loss: 0.39246388       [[val]]     loss: 0.38462323       \n",
      "[[step     2220]]     [[train]]     loss: 0.39198503       [[val]]     loss: 0.38449875       \n",
      "[[step     2230]]     [[train]]     loss: 0.3917676        [[val]]     loss: 0.38464908       \n",
      "[[step     2240]]     [[train]]     loss: 0.39225369       [[val]]     loss: 0.38361986       \n",
      "[[step     2250]]     [[train]]     loss: 0.39031957       [[val]]     loss: 0.38305873       \n",
      "[[step     2260]]     [[train]]     loss: 0.388043         [[val]]     loss: 0.38298882       \n",
      "[[step     2270]]     [[train]]     loss: 0.38773393       [[val]]     loss: 0.38185417       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step     2280]]     [[train]]     loss: 0.38565964       [[val]]     loss: 0.38291228       \n",
      "[[step     2290]]     [[train]]     loss: 0.38635397       [[val]]     loss: 0.38233616       \n",
      "[[step     2300]]     [[train]]     loss: 0.38677793       [[val]]     loss: 0.38155866       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step     2310]]     [[train]]     loss: 0.38340877       [[val]]     loss: 0.38147762       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step     2320]]     [[train]]     loss: 0.38335122       [[val]]     loss: 0.38138155       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step     2330]]     [[train]]     loss: 0.38423972       [[val]]     loss: 0.38143579       \n",
      "[[step     2340]]     [[train]]     loss: 0.38381057       [[val]]     loss: 0.38146028       \n",
      "[[step     2350]]     [[train]]     loss: 0.38474918       [[val]]     loss: 0.38199338       \n",
      "[[step     2360]]     [[train]]     loss: 0.38479082       [[val]]     loss: 0.3827367        \n",
      "[[step     2370]]     [[train]]     loss: 0.38396708       [[val]]     loss: 0.38342732       \n",
      "[[step     2380]]     [[train]]     loss: 0.38638799       [[val]]     loss: 0.38425991       \n",
      "[[step     2390]]     [[train]]     loss: 0.38591729       [[val]]     loss: 0.38390055       \n",
      "[[step     2400]]     [[train]]     loss: 0.38504379       [[val]]     loss: 0.38334771       \n",
      "[[step     2410]]     [[train]]     loss: 0.3874464        [[val]]     loss: 0.3837407        \n",
      "[[step     2420]]     [[train]]     loss: 0.38782966       [[val]]     loss: 0.38449156       \n",
      "[[step     2430]]     [[train]]     loss: 0.38789345       [[val]]     loss: 0.38494342       \n",
      "[[step     2440]]     [[train]]     loss: 0.38810482       [[val]]     loss: 0.38589154       \n",
      "[[step     2450]]     [[train]]     loss: 0.38836449       [[val]]     loss: 0.38586908       \n",
      "[[step     2460]]     [[train]]     loss: 0.38919681       [[val]]     loss: 0.38538462       \n",
      "[[step     2470]]     [[train]]     loss: 0.39024443       [[val]]     loss: 0.38531224       \n",
      "[[step     2480]]     [[train]]     loss: 0.38937188       [[val]]     loss: 0.38487404       \n",
      "[[step     2490]]     [[train]]     loss: 0.38892171       [[val]]     loss: 0.38484322       \n",
      "[[step     2500]]     [[train]]     loss: 0.38819477       [[val]]     loss: 0.38372279       \n",
      "[[step     2510]]     [[train]]     loss: 0.38665974       [[val]]     loss: 0.38205382       \n",
      "[[step     2520]]     [[train]]     loss: 0.38642741       [[val]]     loss: 0.38154209       \n",
      "[[step     2530]]     [[train]]     loss: 0.38722437       [[val]]     loss: 0.38097871       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step     2540]]     [[train]]     loss: 0.38611036       [[val]]     loss: 0.38005936       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step     2550]]     [[train]]     loss: 0.38788716       [[val]]     loss: 0.37930532       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step     2560]]     [[train]]     loss: 0.38716637       [[val]]     loss: 0.37894312       \n",
      "saving model to ./tf-data/checkpoints/model\n",
      "[[step     2570]]     [[train]]     loss: 0.38797755       [[val]]     loss: 0.38015672       \n",
      "[[step     2580]]     [[train]]     loss: 0.38686557       [[val]]     loss: 0.38012865       \n",
      "[[step     2590]]     [[train]]     loss: 0.38712089       [[val]]     loss: 0.38029601       \n",
      "[[step     2600]]     [[train]]     loss: 0.38722054       [[val]]     loss: 0.38172598       \n",
      "[[step     2610]]     [[train]]     loss: 0.38791159       [[val]]     loss: 0.38212191       \n",
      "[[step     2620]]     [[train]]     loss: 0.38908387       [[val]]     loss: 0.38290975       \n",
      "[[step     2630]]     [[train]]     loss: 0.38841246       [[val]]     loss: 0.38263379       \n",
      "[[step     2640]]     [[train]]     loss: 0.38905628       [[val]]     loss: 0.38357676       \n",
      "[[step     2650]]     [[train]]     loss: 0.3879913        [[val]]     loss: 0.38314355       \n",
      "[[step     2660]]     [[train]]     loss: 0.3878762        [[val]]     loss: 0.38421074       \n",
      "[[step     2670]]     [[train]]     loss: 0.38783387       [[val]]     loss: 0.38340956       \n",
      "[[step     2680]]     [[train]]     loss: 0.38772147       [[val]]     loss: 0.38178187       \n",
      "[[step     2690]]     [[train]]     loss: 0.3882411        [[val]]     loss: 0.38209777       \n",
      "[[step     2700]]     [[train]]     loss: 0.38911013       [[val]]     loss: 0.38389689       \n",
      "[[step     2710]]     [[train]]     loss: 0.38869946       [[val]]     loss: 0.38470357       \n",
      "[[step     2720]]     [[train]]     loss: 0.387615         [[val]]     loss: 0.38469183       \n",
      "[[step     2730]]     [[train]]     loss: 0.38658184       [[val]]     loss: 0.38456922       \n",
      "[[step     2740]]     [[train]]     loss: 0.38709552       [[val]]     loss: 0.38356594       \n",
      "[[step     2750]]     [[train]]     loss: 0.38666539       [[val]]     loss: 0.38453175       \n",
      "[[step     2760]]     [[train]]     loss: 0.38756368       [[val]]     loss: 0.38518759       \n",
      "[[step     2770]]     [[train]]     loss: 0.38662227       [[val]]     loss: 0.38494576       \n",
      "[[step     2780]]     [[train]]     loss: 0.38770585       [[val]]     loss: 0.38507152       \n",
      "[[step     2790]]     [[train]]     loss: 0.38803124       [[val]]     loss: 0.38507404       \n",
      "[[step     2800]]     [[train]]     loss: 0.38713802       [[val]]     loss: 0.38393484       \n",
      "[[step     2810]]     [[train]]     loss: 0.38760046       [[val]]     loss: 0.38473685       \n",
      "[[step     2820]]     [[train]]     loss: 0.38804165       [[val]]     loss: 0.38452368       \n",
      "[[step     2830]]     [[train]]     loss: 0.3888616        [[val]]     loss: 0.3845162        \n",
      "[[step     2840]]     [[train]]     loss: 0.38735402       [[val]]     loss: 0.38516578       \n",
      "[[step     2850]]     [[train]]     loss: 0.38803376       [[val]]     loss: 0.38478779       \n",
      "[[step     2860]]     [[train]]     loss: 0.3877712        [[val]]     loss: 0.38385453       \n",
      "[[step     2870]]     [[train]]     loss: 0.38783411       [[val]]     loss: 0.38336226       \n",
      "[[step     2880]]     [[train]]     loss: 0.3879642        [[val]]     loss: 0.38341552       \n",
      "[[step     2890]]     [[train]]     loss: 0.3870349        [[val]]     loss: 0.38355638       \n",
      "[[step     2900]]     [[train]]     loss: 0.38701453       [[val]]     loss: 0.38340139       \n",
      "[[step     2910]]     [[train]]     loss: 0.38689189       [[val]]     loss: 0.38269103       \n",
      "[[step     2920]]     [[train]]     loss: 0.38658095       [[val]]     loss: 0.38283888       \n",
      "[[step     2930]]     [[train]]     loss: 0.38613129       [[val]]     loss: 0.38359614       \n",
      "[[step     2940]]     [[train]]     loss: 0.38760276       [[val]]     loss: 0.38290035       \n",
      "[[step     2950]]     [[train]]     loss: 0.38605358       [[val]]     loss: 0.38360977       \n",
      "[[step     2960]]     [[train]]     loss: 0.38528822       [[val]]     loss: 0.38441676       \n",
      "[[step     2970]]     [[train]]     loss: 0.38597986       [[val]]     loss: 0.38525308       \n",
      "[[step     2980]]     [[train]]     loss: 0.38701527       [[val]]     loss: 0.38548595       \n",
      "[[step     2990]]     [[train]]     loss: 0.38778741       [[val]]     loss: 0.38537778       \n",
      "[[step     3000]]     [[train]]     loss: 0.38752771       [[val]]     loss: 0.38489231       \n",
      "[[step     3010]]     [[train]]     loss: 0.38547647       [[val]]     loss: 0.38485097       \n",
      "[[step     3020]]     [[train]]     loss: 0.38559543       [[val]]     loss: 0.38464723       \n",
      "[[step     3030]]     [[train]]     loss: 0.38710428       [[val]]     loss: 0.38515266       \n",
      "[[step     3040]]     [[train]]     loss: 0.38648359       [[val]]     loss: 0.38437715       \n",
      "[[step     3050]]     [[train]]     loss: 0.38685914       [[val]]     loss: 0.38431308       \n",
      "[[step     3060]]     [[train]]     loss: 0.38661          [[val]]     loss: 0.38349057       \n",
      "[[step     3070]]     [[train]]     loss: 0.38610977       [[val]]     loss: 0.38381724       \n",
      "restoring model from ./tf-data/checkpoints/model-2560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tf-data/checkpoints/model-2560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "halving learning rate\n",
      "[[step     2570]]     [[train]]     loss: 0.38462843       [[val]]     loss: 0.38407839       \n",
      "[[step     2580]]     [[train]]     loss: 0.38385752       [[val]]     loss: 0.38355519       \n",
      "[[step     2590]]     [[train]]     loss: 0.38443792       [[val]]     loss: 0.38309681       \n",
      "[[step     2600]]     [[train]]     loss: 0.38667188       [[val]]     loss: 0.38248799       \n",
      "[[step     2610]]     [[train]]     loss: 0.38647393       [[val]]     loss: 0.38213151       \n",
      "[[step     2620]]     [[train]]     loss: 0.38481492       [[val]]     loss: 0.38107591       \n",
      "[[step     2630]]     [[train]]     loss: 0.38515978       [[val]]     loss: 0.38200959       \n",
      "[[step     2640]]     [[train]]     loss: 0.38589236       [[val]]     loss: 0.38168371       \n",
      "[[step     2650]]     [[train]]     loss: 0.38636651       [[val]]     loss: 0.38185505       \n",
      "[[step     2660]]     [[train]]     loss: 0.38578927       [[val]]     loss: 0.38083021       \n",
      "[[step     2670]]     [[train]]     loss: 0.38553167       [[val]]     loss: 0.3803991        \n",
      "[[step     2680]]     [[train]]     loss: 0.38526422       [[val]]     loss: 0.38127133       \n",
      "[[step     2690]]     [[train]]     loss: 0.38459958       [[val]]     loss: 0.38329209       \n",
      "[[step     2700]]     [[train]]     loss: 0.38457229       [[val]]     loss: 0.38320391       \n",
      "[[step     2710]]     [[train]]     loss: 0.38479426       [[val]]     loss: 0.38371313       \n",
      "[[step     2720]]     [[train]]     loss: 0.38446233       [[val]]     loss: 0.38356589       \n",
      "[[step     2730]]     [[train]]     loss: 0.38449353       [[val]]     loss: 0.38276239       \n",
      "[[step     2740]]     [[train]]     loss: 0.38422977       [[val]]     loss: 0.38319634       \n",
      "[[step     2750]]     [[train]]     loss: 0.38310557       [[val]]     loss: 0.38272068       \n",
      "[[step     2760]]     [[train]]     loss: 0.38338005       [[val]]     loss: 0.38336528       \n",
      "[[step     2770]]     [[train]]     loss: 0.38416246       [[val]]     loss: 0.38373597       \n",
      "[[step     2780]]     [[train]]     loss: 0.38512072       [[val]]     loss: 0.38431258       \n",
      "[[step     2790]]     [[train]]     loss: 0.38623739       [[val]]     loss: 0.3820294        \n",
      "[[step     2800]]     [[train]]     loss: 0.38504545       [[val]]     loss: 0.38343668       \n",
      "[[step     2810]]     [[train]]     loss: 0.3848985        [[val]]     loss: 0.38270107       \n",
      "[[step     2820]]     [[train]]     loss: 0.38513667       [[val]]     loss: 0.3829256        \n",
      "[[step     2830]]     [[train]]     loss: 0.3863046        [[val]]     loss: 0.38362064       \n",
      "[[step     2840]]     [[train]]     loss: 0.38507836       [[val]]     loss: 0.38242522       \n",
      "[[step     2850]]     [[train]]     loss: 0.3870113        [[val]]     loss: 0.38269257       \n",
      "[[step     2860]]     [[train]]     loss: 0.38639623       [[val]]     loss: 0.38218066       \n",
      "[[step     2870]]     [[train]]     loss: 0.38689788       [[val]]     loss: 0.38150076       \n",
      "[[step     2880]]     [[train]]     loss: 0.38664796       [[val]]     loss: 0.38045547       \n",
      "[[step     2890]]     [[train]]     loss: 0.3876504        [[val]]     loss: 0.38124071       \n",
      "[[step     2900]]     [[train]]     loss: 0.3873912        [[val]]     loss: 0.37983099       \n",
      "[[step     2910]]     [[train]]     loss: 0.38756596       [[val]]     loss: 0.38070199       \n",
      "[[step     2920]]     [[train]]     loss: 0.38747844       [[val]]     loss: 0.38006327       \n",
      "[[step     2930]]     [[train]]     loss: 0.38668522       [[val]]     loss: 0.38025478       \n",
      "[[step     2940]]     [[train]]     loss: 0.38635341       [[val]]     loss: 0.38074403       \n",
      "[[step     2950]]     [[train]]     loss: 0.38443162       [[val]]     loss: 0.38042089       \n",
      "[[step     2960]]     [[train]]     loss: 0.38454535       [[val]]     loss: 0.37993188       \n",
      "[[step     2970]]     [[train]]     loss: 0.38309269       [[val]]     loss: 0.38036386       \n",
      "[[step     2980]]     [[train]]     loss: 0.38207467       [[val]]     loss: 0.38103766       \n",
      "[[step     2990]]     [[train]]     loss: 0.38081145       [[val]]     loss: 0.38111792       \n",
      "[[step     3000]]     [[train]]     loss: 0.38226848       [[val]]     loss: 0.38076375       \n",
      "[[step     3010]]     [[train]]     loss: 0.38241507       [[val]]     loss: 0.37936086       \n",
      "[[step     3020]]     [[train]]     loss: 0.38358402       [[val]]     loss: 0.38054544       \n",
      "[[step     3030]]     [[train]]     loss: 0.3830247        [[val]]     loss: 0.37989434       \n",
      "[[step     3040]]     [[train]]     loss: 0.38495331       [[val]]     loss: 0.37999057       \n",
      "[[step     3050]]     [[train]]     loss: 0.38575768       [[val]]     loss: 0.37991253       \n",
      "[[step     3060]]     [[train]]     loss: 0.38579613       [[val]]     loss: 0.38013638       \n",
      "[[step     3070]]     [[train]]     loss: 0.38634042       [[val]]     loss: 0.37924307       \n",
      "best validation loss of 0.37894312143325803 at training step 2560\n",
      "early stopping - ending training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training ends at: 2018-01-23.23-09-42.006529\n"
     ]
    }
   ],
   "source": [
    "print('training start at:', datetime.now().strftime('%Y-%m-%d.%H-%M-%S.%f'))\n",
    "nn.fit()\n",
    "print('training ends at:', datetime.now().strftime('%Y-%m-%d.%H-%M-%S.%f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "\n",
      "new run with parameters:\n",
      "{'batch_size': 128,\n",
      " 'checkpoint_dir': './tf-data/checkpoints',\n",
      " 'dilations': [1,\n",
      "               2,\n",
      "               4,\n",
      "               8,\n",
      "               16,\n",
      "               32,\n",
      "               64,\n",
      "               128,\n",
      "               1,\n",
      "               2,\n",
      "               4,\n",
      "               8,\n",
      "               16,\n",
      "               32,\n",
      "               64,\n",
      "               128,\n",
      "               1,\n",
      "               2,\n",
      "               4,\n",
      "               8,\n",
      "               16,\n",
      "               32,\n",
      "               64,\n",
      "               128],\n",
      " 'early_stopping_steps': 500,\n",
      " 'enable_parameter_averaging': False,\n",
      " 'filter_widths': [2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2,\n",
      "                   2],\n",
      " 'grad_clip': 20,\n",
      " 'keep_prob_scalar': 1.0,\n",
      " 'learning_rate': 0.001,\n",
      " 'log_dir': './tf-data/logs',\n",
      " 'log_interval': 10,\n",
      " 'loss_averaging_window': 100,\n",
      " 'min_steps_to_checkpoint': 100,\n",
      " 'num_decode_steps': 64,\n",
      " 'num_restarts': 2,\n",
      " 'num_training_steps': 20000,\n",
      " 'num_validation_batches': 1,\n",
      " 'optimizer': 'adam',\n",
      " 'prediction_dir': './tf-data/predictions',\n",
      " 'reader': <datareader.DataReader object at 0x7f649c015898>,\n",
      " 'regularization_constant': 0.0,\n",
      " 'residual_channels': 32,\n",
      " 'skip_channels': 32,\n",
      " 'warm_start_init_step': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size 137809\n",
      "val size 7254\n",
      "test size 145063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "all parameters:\n",
      "[('Variable:0', []),\n",
      " ('Variable_1:0', []),\n",
      " ('x-proj-encode/weights:0', [18, 32]),\n",
      " ('x-proj-encode/biases:0', [32]),\n",
      " ('dilated-conv-encode-0/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-0/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-0/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-0/biases:0', [64]),\n",
      " ('dilated-conv-encode-1/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-1/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-1/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-1/biases:0', [64]),\n",
      " ('dilated-conv-encode-2/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-2/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-2/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-2/biases:0', [64]),\n",
      " ('dilated-conv-encode-3/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-3/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-3/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-3/biases:0', [64]),\n",
      " ('dilated-conv-encode-4/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-4/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-4/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-4/biases:0', [64]),\n",
      " ('dilated-conv-encode-5/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-5/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-5/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-5/biases:0', [64]),\n",
      " ('dilated-conv-encode-6/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-6/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-6/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-6/biases:0', [64]),\n",
      " ('dilated-conv-encode-7/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-7/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-7/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-7/biases:0', [64]),\n",
      " ('dilated-conv-encode-8/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-8/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-8/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-8/biases:0', [64]),\n",
      " ('dilated-conv-encode-9/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-9/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-9/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-9/biases:0', [64]),\n",
      " ('dilated-conv-encode-10/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-10/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-10/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-10/biases:0', [64]),\n",
      " ('dilated-conv-encode-11/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-11/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-11/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-11/biases:0', [64]),\n",
      " ('dilated-conv-encode-12/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-12/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-12/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-12/biases:0', [64]),\n",
      " ('dilated-conv-encode-13/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-13/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-13/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-13/biases:0', [64]),\n",
      " ('dilated-conv-encode-14/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-14/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-14/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-14/biases:0', [64]),\n",
      " ('dilated-conv-encode-15/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-15/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-15/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-15/biases:0', [64]),\n",
      " ('dilated-conv-encode-16/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-16/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-16/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-16/biases:0', [64]),\n",
      " ('dilated-conv-encode-17/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-17/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-17/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-17/biases:0', [64]),\n",
      " ('dilated-conv-encode-18/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-18/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-18/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-18/biases:0', [64]),\n",
      " ('dilated-conv-encode-19/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-19/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-19/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-19/biases:0', [64]),\n",
      " ('dilated-conv-encode-20/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-20/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-20/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-20/biases:0', [64]),\n",
      " ('dilated-conv-encode-21/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-21/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-21/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-21/biases:0', [64]),\n",
      " ('dilated-conv-encode-22/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-22/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-22/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-22/biases:0', [64]),\n",
      " ('dilated-conv-encode-23/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-23/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-23/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-23/biases:0', [64]),\n",
      " ('dense-encode-1/weights:0', [768, 128]),\n",
      " ('dense-encode-1/biases:0', [128]),\n",
      " ('dense-encode-2/weights:0', [128, 1]),\n",
      " ('dense-encode-2/biases:0', [1]),\n",
      " ('x-proj-decode/weights:0', [80, 32]),\n",
      " ('x-proj-decode/biases:0', [32]),\n",
      " ('dilated-conv-decode-0/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-0/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-0/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-0/biases:0', [64]),\n",
      " ('dilated-conv-decode-1/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-1/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-1/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-1/biases:0', [64]),\n",
      " ('dilated-conv-decode-2/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-2/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-2/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-2/biases:0', [64]),\n",
      " ('dilated-conv-decode-3/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-3/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-3/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-3/biases:0', [64]),\n",
      " ('dilated-conv-decode-4/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-4/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-4/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-4/biases:0', [64]),\n",
      " ('dilated-conv-decode-5/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-5/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-5/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-5/biases:0', [64]),\n",
      " ('dilated-conv-decode-6/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-6/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-6/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-6/biases:0', [64]),\n",
      " ('dilated-conv-decode-7/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-7/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-7/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-7/biases:0', [64]),\n",
      " ('dilated-conv-decode-8/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-8/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-8/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-8/biases:0', [64]),\n",
      " ('dilated-conv-decode-9/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-9/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-9/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-9/biases:0', [64]),\n",
      " ('dilated-conv-decode-10/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-10/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-10/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-10/biases:0', [64]),\n",
      " ('dilated-conv-decode-11/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-11/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-11/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-11/biases:0', [64]),\n",
      " ('dilated-conv-decode-12/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-12/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-12/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-12/biases:0', [64]),\n",
      " ('dilated-conv-decode-13/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-13/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-13/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-13/biases:0', [64]),\n",
      " ('dilated-conv-decode-14/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-14/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-14/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-14/biases:0', [64]),\n",
      " ('dilated-conv-decode-15/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-15/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-15/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-15/biases:0', [64]),\n",
      " ('dilated-conv-decode-16/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-16/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-16/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-16/biases:0', [64]),\n",
      " ('dilated-conv-decode-17/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-17/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-17/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-17/biases:0', [64]),\n",
      " ('dilated-conv-decode-18/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-18/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-18/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-18/biases:0', [64]),\n",
      " ('dilated-conv-decode-19/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-19/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-19/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-19/biases:0', [64]),\n",
      " ('dilated-conv-decode-20/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-20/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-20/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-20/biases:0', [64]),\n",
      " ('dilated-conv-decode-21/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-21/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-21/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-21/biases:0', [64]),\n",
      " ('dilated-conv-decode-22/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-22/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-22/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-22/biases:0', [64]),\n",
      " ('dilated-conv-decode-23/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-23/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-23/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-23/biases:0', [64]),\n",
      " ('dense-decode-1/weights:0', [768, 128]),\n",
      " ('dense-decode-1/biases:0', [128]),\n",
      " ('dense-decode-2/weights:0', [128, 1]),\n",
      " ('dense-decode-2/biases:0', [1]),\n",
      " ('beta1_power:0', []),\n",
      " ('beta2_power:0', []),\n",
      " ('x-proj-encode/weights/Adam:0', [18, 32]),\n",
      " ('x-proj-encode/weights/Adam_1:0', [18, 32]),\n",
      " ('x-proj-encode/biases/Adam:0', [32]),\n",
      " ('x-proj-encode/biases/Adam_1:0', [32]),\n",
      " ('dilated-conv-encode-0/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-0/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-0/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-0/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-0/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-0/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-0/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-0/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-1/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-1/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-1/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-1/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-1/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-1/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-1/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-1/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-2/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-2/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-2/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-2/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-2/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-2/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-2/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-2/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-3/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-3/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-3/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-3/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-3/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-3/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-3/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-3/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-4/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-4/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-4/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-4/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-4/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-4/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-4/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-4/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-5/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-5/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-5/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-5/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-5/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-5/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-5/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-5/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-6/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-6/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-6/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-6/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-6/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-6/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-6/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-6/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-7/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-7/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-7/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-7/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-7/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-7/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-7/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-7/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-8/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-8/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-8/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-8/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-8/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-8/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-8/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-8/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-9/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-9/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-9/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-9/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-9/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-9/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-9/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-9/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-10/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-10/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-10/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-10/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-10/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-10/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-10/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-10/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-11/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-11/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-11/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-11/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-11/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-11/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-11/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-11/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-12/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-12/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-12/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-12/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-12/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-12/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-12/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-12/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-13/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-13/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-13/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-13/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-13/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-13/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-13/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-13/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-14/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-14/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-14/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-14/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-14/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-14/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-14/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-14/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-15/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-15/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-15/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-15/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-15/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-15/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-15/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-15/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-16/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-16/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-16/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-16/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-16/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-16/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-16/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-16/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-17/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-17/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-17/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-17/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-17/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-17/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-17/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-17/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-18/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-18/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-18/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-18/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-18/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-18/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-18/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-18/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-19/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-19/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-19/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-19/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-19/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-19/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-19/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-19/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-20/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-20/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-20/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-20/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-20/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-20/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-20/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-20/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-21/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-21/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-21/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-21/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-21/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-21/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-21/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-21/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-22/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-22/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-22/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-22/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-22/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-22/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-22/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-22/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-encode-23/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-23/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-23/biases/Adam:0', [64]),\n",
      " ('dilated-conv-encode-23/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-encode-23/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-23/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-23/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-encode-23/biases/Adam_1:0', [64]),\n",
      " ('dense-encode-1/weights/Adam:0', [768, 128]),\n",
      " ('dense-encode-1/weights/Adam_1:0', [768, 128]),\n",
      " ('dense-encode-1/biases/Adam:0', [128]),\n",
      " ('dense-encode-1/biases/Adam_1:0', [128]),\n",
      " ('dense-encode-2/weights/Adam:0', [128, 1]),\n",
      " ('dense-encode-2/weights/Adam_1:0', [128, 1]),\n",
      " ('dense-encode-2/biases/Adam:0', [1]),\n",
      " ('dense-encode-2/biases/Adam_1:0', [1]),\n",
      " ('x-proj-decode/weights/Adam:0', [80, 32]),\n",
      " ('x-proj-decode/weights/Adam_1:0', [80, 32]),\n",
      " ('x-proj-decode/biases/Adam:0', [32]),\n",
      " ('x-proj-decode/biases/Adam_1:0', [32]),\n",
      " ('dilated-conv-decode-0/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-0/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-0/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-0/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-0/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-0/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-0/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-0/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-1/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-1/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-1/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-1/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-1/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-1/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-1/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-1/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-2/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-2/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-2/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-2/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-2/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-2/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-2/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-2/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-3/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-3/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-3/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-3/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-3/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-3/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-3/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-3/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-4/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-4/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-4/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-4/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-4/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-4/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-4/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-4/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-5/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-5/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-5/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-5/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-5/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-5/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-5/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-5/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-6/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-6/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-6/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-6/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-6/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-6/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-6/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-6/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-7/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-7/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-7/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-7/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-7/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-7/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-7/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-7/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-8/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-8/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-8/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-8/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-8/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-8/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-8/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-8/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-9/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-9/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-9/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-9/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-9/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-9/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-9/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-9/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-10/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-10/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-10/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-10/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-10/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-10/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-10/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-10/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-11/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-11/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-11/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-11/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-11/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-11/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-11/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-11/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-12/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-12/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-12/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-12/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-12/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-12/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-12/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-12/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-13/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-13/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-13/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-13/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-13/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-13/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-13/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-13/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-14/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-14/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-14/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-14/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-14/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-14/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-14/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-14/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-15/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-15/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-15/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-15/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-15/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-15/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-15/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-15/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-16/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-16/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-16/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-16/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-16/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-16/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-16/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-16/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-17/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-17/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-17/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-17/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-17/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-17/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-17/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-17/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-18/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-18/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-18/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-18/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-18/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-18/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-18/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-18/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-19/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-19/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-19/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-19/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-19/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-19/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-19/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-19/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-20/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-20/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-20/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-20/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-20/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-20/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-20/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-20/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-21/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-21/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-21/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-21/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-21/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-21/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-21/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-21/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-22/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-22/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-22/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-22/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-22/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-22/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-22/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-22/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-decode-23/weights/Adam:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-23/weights/Adam_1:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-23/biases/Adam:0', [64]),\n",
      " ('dilated-conv-decode-23/biases/Adam_1:0', [64]),\n",
      " ('dilated-conv-proj-decode-23/weights/Adam:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-23/weights/Adam_1:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-23/biases/Adam:0', [64]),\n",
      " ('dilated-conv-proj-decode-23/biases/Adam_1:0', [64]),\n",
      " ('dense-decode-1/weights/Adam:0', [768, 128]),\n",
      " ('dense-decode-1/weights/Adam_1:0', [768, 128]),\n",
      " ('dense-decode-1/biases/Adam:0', [128]),\n",
      " ('dense-decode-1/biases/Adam_1:0', [128]),\n",
      " ('dense-decode-2/weights/Adam:0', [128, 1]),\n",
      " ('dense-decode-2/weights/Adam_1:0', [128, 1]),\n",
      " ('dense-decode-2/biases/Adam:0', [1]),\n",
      " ('dense-decode-2/biases/Adam_1:0', [1])]\n",
      "trainable parameters:\n",
      "[('x-proj-encode/weights:0', [18, 32]),\n",
      " ('x-proj-encode/biases:0', [32]),\n",
      " ('dilated-conv-encode-0/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-0/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-0/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-0/biases:0', [64]),\n",
      " ('dilated-conv-encode-1/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-1/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-1/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-1/biases:0', [64]),\n",
      " ('dilated-conv-encode-2/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-2/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-2/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-2/biases:0', [64]),\n",
      " ('dilated-conv-encode-3/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-3/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-3/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-3/biases:0', [64]),\n",
      " ('dilated-conv-encode-4/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-4/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-4/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-4/biases:0', [64]),\n",
      " ('dilated-conv-encode-5/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-5/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-5/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-5/biases:0', [64]),\n",
      " ('dilated-conv-encode-6/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-6/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-6/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-6/biases:0', [64]),\n",
      " ('dilated-conv-encode-7/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-7/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-7/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-7/biases:0', [64]),\n",
      " ('dilated-conv-encode-8/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-8/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-8/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-8/biases:0', [64]),\n",
      " ('dilated-conv-encode-9/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-9/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-9/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-9/biases:0', [64]),\n",
      " ('dilated-conv-encode-10/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-10/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-10/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-10/biases:0', [64]),\n",
      " ('dilated-conv-encode-11/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-11/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-11/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-11/biases:0', [64]),\n",
      " ('dilated-conv-encode-12/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-12/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-12/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-12/biases:0', [64]),\n",
      " ('dilated-conv-encode-13/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-13/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-13/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-13/biases:0', [64]),\n",
      " ('dilated-conv-encode-14/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-14/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-14/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-14/biases:0', [64]),\n",
      " ('dilated-conv-encode-15/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-15/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-15/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-15/biases:0', [64]),\n",
      " ('dilated-conv-encode-16/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-16/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-16/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-16/biases:0', [64]),\n",
      " ('dilated-conv-encode-17/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-17/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-17/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-17/biases:0', [64]),\n",
      " ('dilated-conv-encode-18/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-18/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-18/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-18/biases:0', [64]),\n",
      " ('dilated-conv-encode-19/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-19/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-19/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-19/biases:0', [64]),\n",
      " ('dilated-conv-encode-20/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-20/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-20/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-20/biases:0', [64]),\n",
      " ('dilated-conv-encode-21/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-21/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-21/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-21/biases:0', [64]),\n",
      " ('dilated-conv-encode-22/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-22/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-22/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-22/biases:0', [64]),\n",
      " ('dilated-conv-encode-23/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-encode-23/biases:0', [64]),\n",
      " ('dilated-conv-proj-encode-23/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-encode-23/biases:0', [64]),\n",
      " ('dense-encode-1/weights:0', [768, 128]),\n",
      " ('dense-encode-1/biases:0', [128]),\n",
      " ('dense-encode-2/weights:0', [128, 1]),\n",
      " ('dense-encode-2/biases:0', [1]),\n",
      " ('x-proj-decode/weights:0', [80, 32]),\n",
      " ('x-proj-decode/biases:0', [32]),\n",
      " ('dilated-conv-decode-0/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-0/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-0/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-0/biases:0', [64]),\n",
      " ('dilated-conv-decode-1/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-1/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-1/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-1/biases:0', [64]),\n",
      " ('dilated-conv-decode-2/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-2/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-2/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-2/biases:0', [64]),\n",
      " ('dilated-conv-decode-3/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-3/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-3/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-3/biases:0', [64]),\n",
      " ('dilated-conv-decode-4/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-4/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-4/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-4/biases:0', [64]),\n",
      " ('dilated-conv-decode-5/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-5/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-5/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-5/biases:0', [64]),\n",
      " ('dilated-conv-decode-6/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-6/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-6/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-6/biases:0', [64]),\n",
      " ('dilated-conv-decode-7/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-7/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-7/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-7/biases:0', [64]),\n",
      " ('dilated-conv-decode-8/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-8/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-8/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-8/biases:0', [64]),\n",
      " ('dilated-conv-decode-9/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-9/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-9/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-9/biases:0', [64]),\n",
      " ('dilated-conv-decode-10/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-10/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-10/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-10/biases:0', [64]),\n",
      " ('dilated-conv-decode-11/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-11/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-11/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-11/biases:0', [64]),\n",
      " ('dilated-conv-decode-12/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-12/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-12/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-12/biases:0', [64]),\n",
      " ('dilated-conv-decode-13/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-13/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-13/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-13/biases:0', [64]),\n",
      " ('dilated-conv-decode-14/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-14/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-14/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-14/biases:0', [64]),\n",
      " ('dilated-conv-decode-15/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-15/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-15/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-15/biases:0', [64]),\n",
      " ('dilated-conv-decode-16/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-16/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-16/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-16/biases:0', [64]),\n",
      " ('dilated-conv-decode-17/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-17/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-17/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-17/biases:0', [64]),\n",
      " ('dilated-conv-decode-18/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-18/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-18/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-18/biases:0', [64]),\n",
      " ('dilated-conv-decode-19/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-19/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-19/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-19/biases:0', [64]),\n",
      " ('dilated-conv-decode-20/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-20/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-20/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-20/biases:0', [64]),\n",
      " ('dilated-conv-decode-21/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-21/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-21/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-21/biases:0', [64]),\n",
      " ('dilated-conv-decode-22/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-22/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-22/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-22/biases:0', [64]),\n",
      " ('dilated-conv-decode-23/weights:0', [2, 32, 64]),\n",
      " ('dilated-conv-decode-23/biases:0', [64]),\n",
      " ('dilated-conv-proj-decode-23/weights:0', [32, 64]),\n",
      " ('dilated-conv-proj-decode-23/biases:0', [64]),\n",
      " ('dense-decode-1/weights:0', [768, 128]),\n",
      " ('dense-decode-1/biases:0', [128]),\n",
      " ('dense-decode-2/weights:0', [128, 1]),\n",
      " ('dense-decode-2/biases:0', [1])]\n",
      "trainable parameter count:\n",
      "501378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "built graph\n"
     ]
    }
   ],
   "source": [
    "reader = DataReader(\n",
    "    data_dir=os.path.join(root, 'processed_full/')\n",
    ")\n",
    "\n",
    "nn = get_nn(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "restoring model parameters from ./tf-data/checkpoints/model-2560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tf-data/checkpoints/model-2560\n"
     ]
    }
   ],
   "source": [
    "nn.restore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1516819933.2566597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "saving priors with shape (145063, 803) to ./tf-data/predictions/priors.npy\n",
      "saving labels with shape (145063, 64) to ./tf-data/predictions/labels.npy\n",
      "saving preds with shape (145063, 64) to ./tf-data/predictions/preds.npy\n",
      "saving page_id with shape (145063,) to ./tf-data/predictions/page_id.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference time: 150.48361659049988\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(start_time)\n",
    "nn.predict()\n",
    "print('inference time:', time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "4 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
